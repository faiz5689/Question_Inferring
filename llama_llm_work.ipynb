{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from groq import Groq\n",
    "import base64\n",
    "import pathlib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "warnings.filterwarnings('ignore', category=InsecureRequestWarning)\n",
    "\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR = pathlib.Path('Data/llama-3.2')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_image_to_base64(image_url):\n",
    "    \"\"\"Convert image to base64 string\"\"\"\n",
    "    response = requests.get(image_url, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "    response.raise_for_status()\n",
    "    return base64.b64encode(response.content).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Of Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_image_features_title(image_url):\n",
    "#     try:\n",
    "#         # Get base64 encoded image\n",
    "#         base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "#         instruction = '''\n",
    "# Reasoning Process for Title Generation:\n",
    "\n",
    "# 1. Initial Observation\n",
    "# - What is immediately visible in the screenshot?\n",
    "# - What IDE/tool is being used or what kind of code is shown?\n",
    "# - Are there any error messages or unusual indicators?\n",
    "\n",
    "# 2. Problem Identification\n",
    "# - What seems to be the main issue?\n",
    "# - Which specific components are involved?\n",
    "# - Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "# 3. Title Formulation\n",
    "# Based on the above analysis, construct a title that:\n",
    "# - Clearly summarizes the main technical issue\n",
    "# - Uses relevant technical keywords\n",
    "# - Is concise and specific\n",
    "# - Takes inspiration from your trained data on stack overflow\n",
    "# - Would be easily searchable\n",
    "\n",
    "# Output Format: \n",
    "# TITLE: <<Generated Title>>\n",
    "# Make sure to start with exactly \"TITLE:\"\n",
    "# '''\n",
    "\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": instruction\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\n",
    "#                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         # Initialize Groq client\n",
    "#         groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "#         client = Groq(api_key=groq_api_key)\n",
    "\n",
    "#         # Make API call\n",
    "#         chat_completion = client.chat.completions.create(\n",
    "#             messages=messages,\n",
    "#             model=\"llama-3.2-90b-vision-preview\",\n",
    "#             temperature=0,\n",
    "#             max_tokens=2048\n",
    "#         )\n",
    "\n",
    "#         # Extract title from response\n",
    "#         generation_prompt = chat_completion.choices[0].message.content\n",
    "#         title = \"\"\n",
    "#         if \"TITLE:\" in generation_prompt:\n",
    "#             title = generation_prompt.split(\"TITLE:\")[1].strip()\n",
    "\n",
    "#         print(title)\n",
    "#         return title\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return \"\"\n",
    "\n",
    "# def calculate_image_features_body(image_url):\n",
    "#     try:\n",
    "#         # Get base64 encoded image\n",
    "#         base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "#         instruction = '''\n",
    "# Reasoning Process for Body Generation:\n",
    "\n",
    "# 1. Initial Observation\n",
    "# - What is immediately visible in the screenshot?\n",
    "# - What IDE/tool is being used or what kind of code is shown?\n",
    "# - Are there any error messages or unusual indicators?\n",
    "\n",
    "# 2. Problem Identification\n",
    "# - What seems to be the main issue?\n",
    "# - Which specific components are involved?\n",
    "# - Is this a configuration, syntax, or runtime issue?\n",
    "\n",
    "# 3. Context Building\n",
    "# - What background or programming information is needed to understand this issue?\n",
    "# - Which framework/language versions are relevant?\n",
    "# - What might have led to this situation?\n",
    "\n",
    "# 4. Solution Attempts Analysis\n",
    "# - What obvious solutions might have been tried?\n",
    "# - What documentation might be relevant?\n",
    "# - What troubleshooting steps would make sense?\n",
    "\n",
    "# 5. Question Body Formulation\n",
    "# Based on the above analysis, construct a detailed body that:\n",
    "# - Clearly explains the context and problem\n",
    "# - Includes all relevant technical details\n",
    "# - Takes inspiration from your trained data on stack overflow\n",
    "# - Shows research effort and attempted solutions\n",
    "# - Is specific and answerable\n",
    "\n",
    "# Output Format: \n",
    "# BODY: <<Generated Body>>\n",
    "# Make sure to start with exactly \"BODY:\"\n",
    "# '''\n",
    "\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": instruction\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\n",
    "#                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         # Initialize Groq client\n",
    "#         groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "#         client = Groq(api_key=groq_api_key)\n",
    "\n",
    "#         # Make API call\n",
    "#         chat_completion = client.chat.completions.create(\n",
    "#             messages=messages,\n",
    "#             model=\"llama-3.2-90b-vision-preview\",\n",
    "#             temperature=0,\n",
    "#             max_tokens=2048\n",
    "#         )\n",
    "\n",
    "#         # Extract body from response\n",
    "#         generation_prompt = chat_completion.choices[0].message.content\n",
    "#         body = \"\"\n",
    "#         if \"BODY:\" in generation_prompt:\n",
    "#             body = generation_prompt.split(\"BODY:\")[1].strip()\n",
    "\n",
    "#         print(body)\n",
    "#         return body\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return \"\"\n",
    "\n",
    "# def process_rows(dataframe):\n",
    "#     total_rows_processed = 0\n",
    "#     results = []  # List to store results\n",
    "    \n",
    "#     # Create log file for tracking progress\n",
    "#     log_file = OUTPUT_DIR / 'processing_log.txt'\n",
    "#     with open(log_file, 'w') as f:\n",
    "#         f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "#     for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc=f'Processing'):\n",
    "#         print(\"\\n\" + \"=\"*50)\n",
    "#         print(f\"Processing Row ID: {row['Id']}\")\n",
    "        \n",
    "#         # Log progress\n",
    "#         with open(log_file, 'a') as f:\n",
    "#             f.write(f\"\\nProcessing Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "#         image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "#         title = row['Title'] \n",
    "#         body = row['Body']\n",
    "        \n",
    "#         # Store LLM responses for all images of this row\n",
    "#         title_responses = []\n",
    "#         body_responses = []\n",
    "        \n",
    "#         for image_url in image_urls:\n",
    "#             print(f\"\\nProcessing image {len(title_responses) + 1}/{len(image_urls)}\")\n",
    "            \n",
    "#             # Generate title\n",
    "#             print(\"Generating title...\")\n",
    "#             title_text = calculate_image_features_title(image_url)\n",
    "#             title_responses.append(title_text)\n",
    "            \n",
    "#             # Generate body\n",
    "#             print(\"Generating body...\")\n",
    "#             body_text = calculate_image_features_body(image_url)\n",
    "#             body_responses.append(body_text)\n",
    "            \n",
    "#             # Log responses\n",
    "#             with open(log_file, 'a') as f:\n",
    "#                 f.write(f\"Processed image {len(title_responses)}/{len(image_urls)}\\n\")\n",
    "#                 f.write(f\"Title response: {title_text}\\n\")\n",
    "#                 f.write(f\"Body response: {body_text}\\n\")\n",
    "        \n",
    "#         # Combine all responses into strings\n",
    "#         combined_title_response = \" ||| \".join(title_responses)\n",
    "#         combined_body_response = \" ||| \".join(body_responses)\n",
    "        \n",
    "#         # Store the results\n",
    "#         results.append({\n",
    "#             'Id': row['Id'],\n",
    "#             'Title': title,\n",
    "#             'Body': body,\n",
    "#             'ImageURLs': row['ImageURLs'],\n",
    "#             'llm_title_response': combined_title_response,\n",
    "#             'llm_body_response': combined_body_response\n",
    "#         })\n",
    "        \n",
    "#         total_rows_processed += 1\n",
    "#         print(f\"Completed processing Row ID: {row['Id']}\")\n",
    "#         print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "#         # Save intermediate results every 2 rows without waiting\n",
    "#         if total_rows_processed % 2 == 0:\n",
    "#             print(\"\\nSaving intermediate results...\")\n",
    "            \n",
    "#             # Save intermediate results\n",
    "#             intermediate_df = pd.DataFrame(results)\n",
    "#             intermediate_file = OUTPUT_DIR / f'intermediate_results_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "#             intermediate_df.to_csv(intermediate_file, index=False)\n",
    "#             print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "            \n",
    "#             # Log intermediate save\n",
    "#             with open(log_file, 'a') as f:\n",
    "#                 f.write(f\"\\nSaved intermediate results after {total_rows_processed} rows at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "#     # Create final DataFrame and save to CSV\n",
    "#     final_df = pd.DataFrame(results)\n",
    "#     final_file = OUTPUT_DIR / f'llm_responses_final_chain_of_thoughts.csv'\n",
    "#     final_df.to_csv(final_file, index=False)\n",
    "#     print(f\"\\nFinal results saved to {final_file}\")\n",
    "    \n",
    "#     # Log completion\n",
    "#     with open(log_file, 'a') as f:\n",
    "#         f.write(f\"\\nProcessing completed at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "#         f.write(f\"Total rows processed: {total_rows_processed}\\n\")\n",
    "    \n",
    "#     return final_df\n",
    "\n",
    "# # Load dataset\n",
    "# load_dotenv()\n",
    "# dataset = pd.read_csv('Data/filtered_data_matched.csv')\n",
    "\n",
    "# # Process the dataset\n",
    "# results_df = process_rows(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import base64\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import matplotlib.image as mpimg\n",
    "import requests\n",
    "\n",
    "# Create output directory structure\n",
    "OUTPUT_DIR = pathlib.Path('Data/llama-3.2/few-shot')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def resize_image(image, max_dimension):\n",
    "    width, height = image.size\n",
    "    if image.mode == \"P\":\n",
    "        if \"transparency\" in image.info:\n",
    "            image = image.convert(\"RGBA\")\n",
    "        else:\n",
    "            image = image.convert(\"RGB\")\n",
    "    if width > max_dimension or height > max_dimension:\n",
    "        if width > height:\n",
    "            new_width = max_dimension\n",
    "            new_height = int(height * (max_dimension / width))\n",
    "        else:\n",
    "            new_height = max_dimension\n",
    "            new_width = int(width * (max_dimension / height))\n",
    "        image = image.resize((new_width, new_height), Image.LANCZOS)\n",
    "    return image\n",
    "\n",
    "def convert_to_png(image):\n",
    "    with io.BytesIO() as output:\n",
    "        image.save(output, format=\"PNG\")\n",
    "        return output.getvalue()\n",
    "\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        return io.BytesIO(response.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def process_image(url, max_size):\n",
    "    try:\n",
    "        # Download image\n",
    "        image_data = download_image(url)\n",
    "        if not image_data:\n",
    "            return None\n",
    "        \n",
    "        with Image.open(image_data) as image:\n",
    "            width, height = image.size\n",
    "            mimetype = image.get_format_mimetype()\n",
    "            \n",
    "            # Convert if not PNG or needs resizing\n",
    "            if mimetype != \"image/png\" or width > max_size or height > max_size:\n",
    "                resized_image = resize_image(image, max_size)\n",
    "                png_image = convert_to_png(resized_image)\n",
    "                return base64.b64encode(png_image).decode('utf-8')\n",
    "            else:\n",
    "                # If already PNG and within size limits\n",
    "                image_data.seek(0)\n",
    "                return base64.b64encode(image_data.read()).decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None\n",
    "\n",
    "def combine_images_vertical(images, max_size):\n",
    "    \"\"\"\n",
    "    Combine multiple images into a vertical collage with labels\n",
    "    \n",
    "    Args:\n",
    "        images: List of image URLs\n",
    "        max_size: Maximum dimension for any single image\n",
    "    \n",
    "    Returns:\n",
    "        Base64 encoded string of the combined image\n",
    "    \"\"\"\n",
    "    # Process each image\n",
    "    processed_images = []\n",
    "    for img_url in images:\n",
    "        processed = process_image(img_url, max_size)\n",
    "        if processed:\n",
    "            processed_images.append(processed)\n",
    "    \n",
    "    if not processed_images:\n",
    "        return None\n",
    "    \n",
    "    # Convert base64 strings back to PIL Images\n",
    "    pil_images = []\n",
    "    for img_data in processed_images:\n",
    "        try:\n",
    "            img_bytes = base64.b64decode(img_data)\n",
    "            img = Image.open(io.BytesIO(img_bytes))\n",
    "            pil_images.append(img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting base64 to image: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if not pil_images:\n",
    "        return None\n",
    "    \n",
    "    # Calculate dimensions for the collage\n",
    "    max_width = max(img.width for img in pil_images)\n",
    "    total_height = sum(img.height for img in pil_images) + (len(pil_images) * 30)  # Extra space for labels\n",
    "    \n",
    "    # Create new image with white background\n",
    "    collage = Image.new(\"RGB\", (max_width, total_height), \"white\")\n",
    "    \n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(collage)\n",
    "    \n",
    "    # Try to load a font, fall back to default if not available\n",
    "    try:\n",
    "        font = ImageFont.truetype(\"arial.ttf\", 20)\n",
    "    except:\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    # Paste images vertically with labels\n",
    "    y_offset = 0\n",
    "    for i, img in enumerate(pil_images, 1):\n",
    "        # Add label\n",
    "        label_text = f\"Image {i}\"\n",
    "        draw.text((10, y_offset), label_text, fill=\"black\", font=font)\n",
    "        y_offset += 30  # Space for label\n",
    "        \n",
    "        # Center the image horizontally\n",
    "        x_offset = (max_width - img.width) // 2\n",
    "        collage.paste(img, (x_offset, y_offset))\n",
    "        y_offset += img.height\n",
    "    \n",
    "    # Convert to base64\n",
    "    buffer = io.BytesIO()\n",
    "    collage.save(buffer, format=\"PNG\")\n",
    "    return base64.b64encode(buffer.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "def combine_and_display_images(images, max_size, save_path=None):\n",
    "    \"\"\"\n",
    "    Combine multiple images vertically, display them, and optionally save\n",
    "    \n",
    "    Args:\n",
    "        images: List of image URLs\n",
    "        max_size: Maximum dimension for any single image\n",
    "        save_path: Optional path to save the combined image\n",
    "    \"\"\"\n",
    "    # Get the combined base64 string\n",
    "    combined_base64 = combine_images_vertical(images, max_size)\n",
    "    \n",
    "    if combined_base64:\n",
    "        # Convert base64 to image\n",
    "        img_data = base64.b64decode(combined_base64)\n",
    "        img = Image.open(io.BytesIO(img_data))\n",
    "        \n",
    "        # # Display using matplotlib\n",
    "        # plt.figure(figsize=(15, 15))\n",
    "        # plt.imshow(img)\n",
    "        # plt.axis('off')\n",
    "        # plt.title('Combined Images with Labels')\n",
    "        # plt.show()\n",
    "        \n",
    "        # Save if path provided\n",
    "        if save_path:\n",
    "            img.save(save_path)\n",
    "            print(f\"Combined image saved to {save_path}\")\n",
    "        \n",
    "        return combined_base64\n",
    "    return None\n",
    "\n",
    "def encode_images_with_examples(target_image_url, display=True):\n",
    "    \"\"\"Combines example images with target image into a single base64 encoded string and displays result\"\"\"\n",
    "    try:\n",
    "        # Example image paths\n",
    "        example_images = [\n",
    "            \"https://i.sstatic.net/rUHWv1Ok.png\",\n",
    "            \"https://i.sstatic.net/TGFPo9Jj.png\"\n",
    "        ]\n",
    "        \n",
    "        # Add target image to the list\n",
    "        all_images = example_images + [target_image_url]\n",
    "        \n",
    "        # Combine and display images\n",
    "        save_path = str(OUTPUT_DIR / f'combined_image_{time.strftime(\"%Y%m%d_%H%M%S\")}.png')\n",
    "        return combine_and_display_images(all_images, 1024, save_path)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error combining images: {e}\")\n",
    "        return None\n",
    "    \n",
    "\n",
    "def calculate_image_features_title(combined_base64):\n",
    "    \"\"\"Generate title using combined image\"\"\"\n",
    "    try:\n",
    "        instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following images and stack overflow post titles as examples:\n",
    "\n",
    "The first two images are examples with their corresponding titles:\n",
    "1. \"Trying to Stack 2 Columns into one Excel\"\n",
    "2. \"is getenv_s not part of cstdlib?\"\n",
    "\n",
    "Now generate a similar title for the third image in the screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise title that summarizes the main issue\n",
    "2. Take inspiration from the example titles given\n",
    "3. Create it based on the third image and not the examples\n",
    "\n",
    "Output Format: \n",
    "TITLE: <<Generated Title>>\n",
    "Make sure to start with exactly \"TITLE:\" \n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": instruction\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{combined_base64}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Initialize Groq client\n",
    "        groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "        client = Groq(api_key=groq_api_key)\n",
    "\n",
    "        # Make API call\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.2-90b-vision-preview\",\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "\n",
    "        # Extract title from response\n",
    "        generation_prompt = chat_completion.choices[0].message.content\n",
    "        title = \"\"\n",
    "        if \"TITLE:\" in generation_prompt:\n",
    "            title = generation_prompt.split(\"TITLE:\")[1].strip()\n",
    "\n",
    "        return title\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating title: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def calculate_image_features_body(combined_base64):\n",
    "    \"\"\"Generate body using combined image\"\"\"\n",
    "    try:\n",
    "        instruction = '''\n",
    "You are an expert software developer and Stack Overflow analyst. You are given the following images and stack overflow post bodies as examples:\n",
    "\n",
    "The first two images are examples with their corresponding bodies:\n",
    "1. \"I am currently attempting to combine two columns into one but have encountered an error that prevents me from completing this task. Additionally, the data from the second column appears to be pasting incorrectly after the error messages.I would greatly appreciate any assistance with this issue.=IF(P2<>\"\",P2,INDEX($R$2:$R$5000,ROW()-COUNTA($P$2:$P$5000)))Column P and R contains formulas.\"\n",
    "\n",
    "2. \"C11 added new bounds-checked functions to the standard library, such as getenv_s.However, when I include <cstdlib>, I do not have std::getenv_s, only getenv_s (global namespace).cppreference has the following note:As with all bounds-checked functions, getenv_s is only guaranteed to be available if __STDC_LIB_EXT1__ is defined by the implementation and if the user defines __STDC_WANT_LIB_EXT1__ to the integer constant 1 before including <stdlib.h>.Even when I define __STDC_WANT_LIB_EXT1__ as 1, My compiler (MSVC C++23) does not find the std::getenv_s function.Isn't <cstdlib> supposed to bring every symbol of <stdlib.h> into the std namespace?\"\n",
    "\n",
    "Now generate a similar question body for the third image in the screenshot:\n",
    "Follow the pattern:\n",
    "1. Clear and concise issue report that explains the issue in detail\n",
    "2. What is the most important part of an error that can be present in the image?\n",
    "3. Take inspiration from the example report given\n",
    "4. Create it based on the image and not the examples and generate some response\n",
    "5. NOTE!! Generate some response for the third image!!\n",
    "\n",
    "\n",
    "Output Format: \n",
    "BODY: <<Generated Body>>\n",
    "Make sure to start with exactly \"BODY:\" and generate something no matter what.\n",
    "'''\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": instruction\n",
    "                    },\n",
    "                    {\n",
    "                        \"type\": \"image_url\",\n",
    "                        \"image_url\": {\n",
    "                            \"url\": f\"data:image/jpeg;base64,{combined_base64}\"\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        # Initialize Groq client\n",
    "        groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "        client = Groq(api_key=groq_api_key)\n",
    "\n",
    "        # Make API call\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=messages,\n",
    "            model=\"llama-3.2-11b-vision-preview\",\n",
    "            temperature=0,\n",
    "            max_tokens=4096\n",
    "        )\n",
    "\n",
    "        # Extract body from response\n",
    "        generation_prompt = chat_completion.choices[0].message.content\n",
    "        body = \"\"\n",
    "        if \"BODY:\" in generation_prompt:\n",
    "            body = generation_prompt.split(\"BODY:\")[1].strip()\n",
    "\n",
    "        return body\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error generating body: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_rows(dataframe):\n",
    "    total_rows_processed = 0\n",
    "    results = []\n",
    "    \n",
    "    # Create log file\n",
    "    log_file = OUTPUT_DIR / 'processing_log.txt'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "    for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc='Processing'):\n",
    "        print(f\"\\nProcessing Row ID: {row['Id']}\")\n",
    "        \n",
    "        # Extract image URLs\n",
    "        image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "        \n",
    "        if image_urls:\n",
    "            for image_url in image_urls:\n",
    "                # Combine example images with target image and display\n",
    "                combined_base64 = encode_images_with_examples(image_url)\n",
    "                \n",
    "                if combined_base64:\n",
    "                    # Generate title and body using combined image\n",
    "                    title_response = calculate_image_features_title(combined_base64)\n",
    "                    print(\"TITLE:\\n\" + title_response)\n",
    "                    body_response = calculate_image_features_body(combined_base64)\n",
    "                    print(\"BODY: \\n\" + body_response)\n",
    "                    \n",
    "                    # Store results\n",
    "                    results.append({\n",
    "                        'Id': row['Id'],\n",
    "                        'Title': row['Title'],\n",
    "                        'Body': row['Body'],\n",
    "                        'ImageURLs': row['ImageURLs'],\n",
    "                        'llm_title_response': title_response,\n",
    "                        'llm_body_response': body_response\n",
    "                    })\n",
    "                    \n",
    "                    # Log progress\n",
    "                    with open(log_file, 'a') as f:\n",
    "                        f.write(f\"\\nProcessed Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "                        f.write(f\"Title response: {title_response}\\n\")\n",
    "                        f.write(f\"Body response: {body_response}\\n\")\n",
    "                    \n",
    "                    total_rows_processed += 1\n",
    "                    \n",
    "                    # Save intermediate results every 2 rows\n",
    "                    if total_rows_processed % 2 == 0:\n",
    "                        intermediate_df = pd.DataFrame(results)\n",
    "                        intermediate_file = OUTPUT_DIR / f'intermediate_results_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "                        intermediate_df.to_csv(intermediate_file, index=False)\n",
    "                        print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "        \n",
    "        print(f\"Completed processing Row ID: {row['Id']}\")\n",
    "    \n",
    "    # Save final results\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_file = OUTPUT_DIR / 'llm_responses_final_few_shot.csv'\n",
    "    final_df.to_csv(final_file, index=False)\n",
    "    \n",
    "    # Log completion\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(f\"\\nProcessing completed at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        f.write(f\"Total rows processed: {total_rows_processed}\\n\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()\n",
    "    dataset = pd.read_csv('Data/filtered_data_matched.csv')\n",
    "    results_df = process_rows(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IN-Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clear any existing environment variables\n",
    "# os.environ.pop('GROQ_API_KEY', None)  # Safely remove if exists\n",
    "\n",
    "# # Force reload of .env file\n",
    "# load_dotenv(override=True)  # This will override existing env variables\n",
    "\n",
    "# # Verify the API key\n",
    "# groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "# if groq_api_key:\n",
    "#     print(\"New API key loaded successfully\")\n",
    "# else:\n",
    "#     print(\"Failed to load API key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize Groq client\n",
    "# groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "# client = Groq(api_key=groq_api_key)\n",
    "\n",
    "# def calculate_image_features_title(image_url):\n",
    "#     try:\n",
    "#         # Get base64 encoded image\n",
    "#         base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "#         instruction = '''\n",
    "# Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "# Generate a Stack Overflow title that:\n",
    "# 1. Follows Stack Overflow guidelines\n",
    "# 2. Is clear and concise\n",
    "# 3. Summarizes the main technical issue shown\n",
    "# 4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "# Output Format: \n",
    "# TITLE: <<Generated Title>>\n",
    "\n",
    "# Make sure to start with exactly \"TITLE:\"\n",
    "# '''\n",
    "\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": instruction\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\n",
    "#                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "\n",
    "#         # Make API call\n",
    "#         chat_completion = client.chat.completions.create(\n",
    "#             messages=messages,\n",
    "#             model=\"llama-3.2-90b-vision-preview\",\n",
    "#             temperature=0,\n",
    "#             max_tokens=2048\n",
    "#         )\n",
    "\n",
    "#         # Extract title from response\n",
    "#         generation_prompt = chat_completion.choices[0].message.content\n",
    "#         title = \"\"\n",
    "#         if \"TITLE:\" in generation_prompt:\n",
    "#             title = generation_prompt.split(\"TITLE:\")[1].strip()\n",
    "\n",
    "#         print(title)\n",
    "#         return title\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return \"\"\n",
    "\n",
    "# def calculate_image_features_body(image_url):\n",
    "#     try:\n",
    "#         # Get base64 encoded image\n",
    "#         base64_image = encode_image_to_base64(image_url)\n",
    "\n",
    "#         instruction = '''\n",
    "# Context: You are an expert programmer experienced in different technology stacks. You encountered an issue while working on a project. The screenshot shows the problem but you are not given any textual content.\n",
    "# Generate a detailed Stack Overflow question body that:\n",
    "# 1. Follows Stack Overflow guidelines\n",
    "# 2. Includes relevant code/IDE context\n",
    "# 3. Clearly states the expected vs. actual behavior\n",
    "# 4. Take inspiration from your trained data for stack overflow.\n",
    "\n",
    "# Output Format: \n",
    "# BODY: <<Generated Body>>\n",
    "\n",
    "# Make sure to start with exactly \"BODY:\"\n",
    "# '''\n",
    "\n",
    "#         messages = [\n",
    "#             {\n",
    "#                 \"role\": \"user\",\n",
    "#                 \"content\": [\n",
    "#                     {\n",
    "#                         \"type\": \"text\",\n",
    "#                         \"text\": instruction\n",
    "#                     },\n",
    "#                     {\n",
    "#                         \"type\": \"image_url\",\n",
    "#                         \"image_url\": {\n",
    "#                             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#                         }\n",
    "#                     }\n",
    "#                 ]\n",
    "#             }\n",
    "#         ]\n",
    "\n",
    "#         # Make API call\n",
    "#         chat_completion = client.chat.completions.create(\n",
    "#             messages=messages,\n",
    "#             model=\"llama-3.2-90b-vision-preview\",\n",
    "#             temperature=0,\n",
    "#             max_tokens=2048\n",
    "#         )\n",
    "\n",
    "#         # Extract body from response\n",
    "#         generation_prompt = chat_completion.choices[0].message.content\n",
    "#         body = \"\"\n",
    "#         if \"BODY:\" in generation_prompt:\n",
    "#             body = generation_prompt.split(\"BODY:\")[1].strip()\n",
    "\n",
    "#         print(body)\n",
    "#         return body\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return \"\"\n",
    "\n",
    "# def process_rows(dataframe):\n",
    "#     total_rows_processed = 0\n",
    "#     results = []  # List to store results\n",
    "    \n",
    "#     # Create log file for tracking progress\n",
    "#     log_file = OUTPUT_DIR / 'processing_log.txt'\n",
    "#     with open(log_file, 'w') as f:\n",
    "#         f.write(f\"Processing started at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "#     for i, row in tqdm(dataframe.iterrows(), total=dataframe.shape[0], desc=f'Processing'):\n",
    "#         # Add 1-minute delay after every 50 rows\n",
    "#         if total_rows_processed > 0 and total_rows_processed % 50 == 0:\n",
    "#             print(\"\\nProcessed 50 rows. Taking a 1-minute break...\")\n",
    "#             with open(log_file, 'a') as f:\n",
    "#                 f.write(f\"\\nTaking a 1-minute break after {total_rows_processed} rows at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "#             time.sleep(60)  # 60 seconds = 1 minute\n",
    "#             print(\"Resuming processing...\")\n",
    "        \n",
    "#         print(\"\\n\" + \"=\"*50)\n",
    "#         print(f\"Processing Row ID: {row['Id']}\")\n",
    "        \n",
    "#         # Log progress\n",
    "#         with open(log_file, 'a') as f:\n",
    "#             f.write(f\"\\nProcessing Row ID: {row['Id']} at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "        \n",
    "#         image_urls = [url.strip(\",\") for url in re.findall(r\"'([^']*)'\", str(row.get('ImageURLs')))]\n",
    "#         title = row['Title'] \n",
    "#         body = row['Body']\n",
    "        \n",
    "#         # Store LLM responses for all images of this row\n",
    "#         title_responses = []\n",
    "#         body_responses = []\n",
    "        \n",
    "#         for image_url in image_urls:\n",
    "#             print(f\"\\nProcessing image {len(title_responses) + 1}/{len(image_urls)}\")\n",
    "            \n",
    "#             # Generate title\n",
    "#             print(\"Generating title...\")\n",
    "#             title_text = calculate_image_features_title(image_url)\n",
    "#             title_responses.append(title_text)\n",
    "            \n",
    "#             # Generate body\n",
    "#             print(\"Generating body...\")\n",
    "#             body_text = calculate_image_features_body(image_url)\n",
    "#             body_responses.append(body_text)\n",
    "            \n",
    "#             # Log responses\n",
    "#             with open(log_file, 'a') as f:\n",
    "#                 f.write(f\"Processed image {len(title_responses)}/{len(image_urls)}\\n\")\n",
    "#                 f.write(f\"Title response: {title_text}\\n\")\n",
    "#                 f.write(f\"Body response: {body_text}\\n\")\n",
    "        \n",
    "#         # Combine all responses into strings\n",
    "#         combined_title_response = \" ||| \".join(title_responses)\n",
    "#         combined_body_response = \" ||| \".join(body_responses)\n",
    "        \n",
    "#         # Store the results\n",
    "#         results.append({\n",
    "#             'Id': row['Id'],\n",
    "#             'Title': title,\n",
    "#             'Body': body,\n",
    "#             'ImageURLs': row['ImageURLs'],\n",
    "#             'llm_title_response': combined_title_response,\n",
    "#             'llm_body_response': combined_body_response\n",
    "#         })\n",
    "        \n",
    "#         total_rows_processed += 1\n",
    "#         print(f\"Completed processing Row ID: {row['Id']}\")\n",
    "#         print(\"=\"*50 + \"\\n\")\n",
    "        \n",
    "#         # Save intermediate results every 2 rows without waiting\n",
    "#         if total_rows_processed % 2 == 0:\n",
    "#             print(\"\\nSaving intermediate results...\")\n",
    "            \n",
    "#             # Save intermediate results\n",
    "#             intermediate_df = pd.DataFrame(results)\n",
    "#             intermediate_file = OUTPUT_DIR / f'intermediate_results_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "#             intermediate_df.to_csv(intermediate_file, index=False)\n",
    "#             print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "            \n",
    "#             # Log intermediate save\n",
    "#             with open(log_file, 'a') as f:\n",
    "#                 f.write(f\"\\nSaved intermediate results after {total_rows_processed} rows at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    \n",
    "#     # Create final DataFrame and save to CSV\n",
    "#     final_df = pd.DataFrame(results)\n",
    "#     final_file = OUTPUT_DIR / f'llm_responses_final_zero_shot.csv'\n",
    "#     final_df.to_csv(final_file, index=False)\n",
    "#     print(f\"\\nFinal results saved to {final_file}\")\n",
    "    \n",
    "#     # Log completion\n",
    "#     with open(log_file, 'a') as f:\n",
    "#         f.write(f\"\\nProcessing completed at {time.strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "#         f.write(f\"Total rows processed: {total_rows_processed}\\n\")\n",
    "    \n",
    "#     return final_df\n",
    "\n",
    "# # Load dataset\n",
    "# load_dotenv()\n",
    "# dataset = pd.read_csv('Data/filtered_data_matched.csv')\n",
    "\n",
    "# # Process the dataset\n",
    "# results_df = process_rows(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 143 entries, 0 to 142\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Id                  143 non-null    int64 \n",
      " 1   Title               143 non-null    object\n",
      " 2   Body                143 non-null    object\n",
      " 3   ImageURLs           143 non-null    object\n",
      " 4   llm_title_response  143 non-null    object\n",
      " 5   llm_body_response   143 non-null    object\n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 6.8+ KB\n"
     ]
    }
   ],
   "source": [
    "results_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
