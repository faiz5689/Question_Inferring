{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Standard Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Third-party Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Image Processing\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "### Data Manipulation and Analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "### Text Processing\n",
    "from spellchecker import SpellChecker\n",
    "from Levenshtein import distance\n",
    "from thefuzz import fuzz\n",
    "import ast\n",
    "\n",
    "### API and Environment\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from json_repair import repair_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Google Cloud and Vertex AI Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.api_core.client_options import ClientOptions\n",
    "from google.cloud import vision\n",
    "import vertexai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR and Text Processing\n",
    "## OCR Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_blocks(annotation):\n",
    "    \"\"\"Extracts blocks, their bounding boxes, and words with coordinates from the annotation.\"\"\"\n",
    "    blocks = []\n",
    "    for page in annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            block_text = ''\n",
    "            words_with_coords = []\n",
    "            \n",
    "            for paragraph in block.paragraphs:\n",
    "                for word in paragraph.words:\n",
    "                    # Combine symbols to form the word text\n",
    "                    word_text = ''.join(symbol.text for symbol in word.symbols)\n",
    "                    \n",
    "                    # Ensure correct order of coordinates\n",
    "                    x_coords = [vertex.x for vertex in word.bounding_box.vertices]\n",
    "                    y_coords = [vertex.y for vertex in word.bounding_box.vertices]\n",
    "                    top_left = (min(x_coords), min(y_coords))\n",
    "                    bottom_right = (max(x_coords), max(y_coords))\n",
    "                    \n",
    "                    words_with_coords.append({\"text\": word_text, \"bounds\": [top_left, bottom_right]})\n",
    "                    block_text += word_text + ' '\n",
    "                \n",
    "                # Add a newline after each paragraph\n",
    "                block_text += '\\n'\n",
    "\n",
    "            # Ensure correct order of coordinates for block\n",
    "            b_x_coords = [vertex.x for vertex in block.bounding_box.vertices]\n",
    "            b_y_coords = [vertex.y for vertex in block.bounding_box.vertices]\n",
    "            b_top_left = (min(b_x_coords), min(b_y_coords))\n",
    "            b_bottom_right = (max(b_x_coords), max(b_y_coords))\n",
    "\n",
    "            # Append the processed block information\n",
    "            blocks.append({\n",
    "                \"text\": block_text.strip(),\n",
    "                \"bounds\": [b_top_left, b_bottom_right],\n",
    "                \"words\": words_with_coords\n",
    "            })\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(image, project_id):\n",
    "    # Create client options with the specified project ID\n",
    "    client_options = ClientOptions(quota_project_id=project_id)\n",
    "    \n",
    "    # Initialize the Vision API client with the specified options\n",
    "    client = vision.ImageAnnotatorClient(client_options=client_options)\n",
    "\n",
    "    # Perform document text detection on the provided image\n",
    "    response = client.document_text_detection(image=image)\n",
    "    \n",
    "    # Extract blocks of text from the full text annotation\n",
    "    blocks = extract_blocks(response.full_text_annotation)\n",
    "    \n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_detect_text(images, project_id):\n",
    "    # Create client options with the specified project ID\n",
    "    client_options = ClientOptions(quota_project_id=project_id)\n",
    "    \n",
    "    # Initialize the Vision API client with the specified options\n",
    "    client = vision.ImageAnnotatorClient(client_options=client_options)\n",
    "    \n",
    "    # Prepare a list of AnnotateImageRequest objects for batch processing\n",
    "    requests = [vision.AnnotateImageRequest(\n",
    "        image=image, \n",
    "        features=[vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)]\n",
    "    ) for image in images]\n",
    "    \n",
    "    # Perform batch annotation of images\n",
    "    response = client.batch_annotate_images(requests=requests)\n",
    "    \n",
    "    # Extract blocks from each response and return as a list\n",
    "    return [extract_blocks(resp.full_text_annotation) for resp in response.responses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OCR Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bounds(words):\n",
    "    \"\"\"Calculate the bounding box for a group of words.\"\"\"\n",
    "    # If there are no words, return a default bounding box of zero size\n",
    "    if not words:\n",
    "        return [(0, 0), (0, 0)]\n",
    "    \n",
    "    # Initialize the bounding box with the first word's bounds\n",
    "    top_left = list(words[0]['bounds'][0])\n",
    "    bottom_right = list(words[0]['bounds'][1])\n",
    "    \n",
    "    # Iterate through the remaining words to expand the bounding box\n",
    "    for word in words[1:]:\n",
    "        # Update the top-left corner (minimum x and y coordinates)\n",
    "        top_left[0] = min(top_left[0], word['bounds'][0][0])\n",
    "        top_left[1] = min(top_left[1], word['bounds'][0][1])\n",
    "        # Update the bottom-right corner (maximum x and y coordinates)\n",
    "        bottom_right[0] = max(bottom_right[0], word['bounds'][1][0])\n",
    "        bottom_right[1] = max(bottom_right[1], word['bounds'][1][1])\n",
    "    \n",
    "    # Return the final bounding box as a tuple of tuples\n",
    "    return [(top_left[0], top_left[1]), (bottom_right[0], bottom_right[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_overlapping_words(paragraphs):\n",
    "    # Flatten the list of words from all paragraphs\n",
    "    all_words = []\n",
    "    for paragraph in paragraphs:\n",
    "        all_words.extend((word, paragraph) for word in paragraph['words'])\n",
    "    \n",
    "    def calculate_overlap(box1, box2):\n",
    "        \"\"\"Calculate the overlap ratio between two bounding boxes.\"\"\"\n",
    "        # Find the coordinates of the intersection rectangle\n",
    "        x1 = max(box1[0][0], box2[0][0])\n",
    "        y1 = max(box1[0][1], box2[0][1])\n",
    "        x2 = min(box1[1][0], box2[1][0])\n",
    "        y2 = min(box1[1][1], box2[1][1])\n",
    "        \n",
    "        # Check if there is no overlap\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate the area of intersection\n",
    "        intersection = (x2 - x1) * (y2 - y1)\n",
    "        # Calculate the areas of both boxes\n",
    "        area1 = (box1[1][0] - box1[0][0]) * (box1[1][1] - box1[0][1])\n",
    "        area2 = (box2[1][0] - box2[0][0]) * (box2[1][1] - box2[0][1])\n",
    "        \n",
    "        # Return the overlap ratio\n",
    "        return intersection / min(area1, area2)\n",
    "    \n",
    "    def merge_boxes(box1, box2):\n",
    "        \"\"\"Merge two bounding boxes into one.\"\"\"\n",
    "        return [\n",
    "            (min(box1[0][0], box2[0][0]), min(box1[0][1], box2[0][1])),\n",
    "            (max(box1[1][0], box2[1][0]), max(box1[1][1], box2[1][1]))\n",
    "        ]\n",
    "    \n",
    "    def calculate_area(box):\n",
    "        \"\"\"Calculate the area of a bounding box.\"\"\"\n",
    "        return (box[1][0] - box[0][0]) * (box[1][1] - box[0][1])\n",
    "    \n",
    "    merged_words = []\n",
    "    for word, paragraph in all_words:\n",
    "        overlapping_word = None\n",
    "        for existing_word, _ in merged_words:\n",
    "            # Check if the current word overlaps significantly with any existing word\n",
    "            if calculate_overlap(word['bounds'], existing_word['bounds']) > 0.5:  # Adjust overlap threshold as needed\n",
    "                overlapping_word = existing_word\n",
    "                break\n",
    "        \n",
    "        if overlapping_word is None:\n",
    "            # If no overlap, add the word as is\n",
    "            merged_words.append((word, paragraph))\n",
    "        else:\n",
    "            # Merge the bounding boxes\n",
    "            merged_bounds = merge_boxes(word['bounds'], overlapping_word['bounds'])\n",
    "            \n",
    "            # Keep the word in the paragraph with the larger area\n",
    "            if calculate_area(word['bounds']) > calculate_area(overlapping_word['bounds']):\n",
    "                merged_words.remove((overlapping_word, _))\n",
    "                merged_words.append(({**word, 'bounds': merged_bounds}, paragraph))\n",
    "            else:\n",
    "                idx = merged_words.index((overlapping_word, _))\n",
    "                merged_words[idx] = ({**overlapping_word, 'bounds': merged_bounds}, _)\n",
    "    \n",
    "    # Reconstruct paragraphs with merged words\n",
    "    new_paragraphs = []\n",
    "    for paragraph in paragraphs:\n",
    "        new_words = [word for word, para in merged_words if para == paragraph]\n",
    "        if new_words:\n",
    "            new_paragraph = paragraph.copy()\n",
    "            new_paragraph['words'] = new_words\n",
    "            new_paragraphs.append(new_paragraph)\n",
    "\n",
    "    # Calculate new bounds for paragraphs\n",
    "    for paragraph in new_paragraphs:\n",
    "        paragraph['bounds'] = calculate_bounds(paragraph['words'])\n",
    "\n",
    "    return new_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_overlapping_paragraphs(paragraphs, word_tolerance=1, paragraph_overlap_threshold=0.5):\n",
    "    def contains_special_characters(word):\n",
    "        \"\"\"Check if a word contains any non-alphabetic characters.\"\"\"\n",
    "        return bool(re.search(r'[^a-zA-Z]', word))\n",
    "\n",
    "    def is_valid_word(word):\n",
    "        \"\"\"Check if a word is valid (contains no special characters and is in the English dictionary).\"\"\"\n",
    "        if contains_special_characters(word):\n",
    "            return False\n",
    "        \n",
    "        from spellchecker import SpellChecker\n",
    "        spell = SpellChecker()\n",
    "        return word in spell\n",
    "\n",
    "    def overlap_horizontally(box1, box2):\n",
    "        \"\"\"Check if two bounding boxes overlap horizontally within the word tolerance.\"\"\"\n",
    "        return (box1[1][0] + word_tolerance >= box2[0][0] and box2[1][0] + word_tolerance >= box1[0][0])\n",
    "\n",
    "    def on_same_line(box1, box2, line_height_tolerance=8):\n",
    "        \"\"\"Check if two bounding boxes are on the same line within the line height tolerance.\"\"\"\n",
    "        return abs(box1[0][1] - box2[0][1]) <= line_height_tolerance\n",
    "\n",
    "    def merge_boxes(box1, box2):\n",
    "        \"\"\"Merge two bounding boxes into one.\"\"\"\n",
    "        return [\n",
    "            (min(box1[0][0], box2[0][0]), min(box1[0][1], box2[0][1])),\n",
    "            (max(box1[1][0], box2[1][0]), max(box1[1][1], box2[1][1]))\n",
    "        ]\n",
    "\n",
    "    def calculate_overlap(box1, box2):\n",
    "        \"\"\"Calculate the overlap ratio between two bounding boxes.\"\"\"\n",
    "        x_overlap = max(0, min(box1[1][0], box2[1][0]) - max(box1[0][0], box2[0][0]))\n",
    "        y_overlap = max(0, min(box1[1][1], box2[1][1]) - max(box1[0][1], box2[0][1]))\n",
    "        overlap_area = x_overlap * y_overlap\n",
    "        \n",
    "        area1 = (box1[1][0] - box1[0][0]) * (box1[1][1] - box1[0][1])\n",
    "        area2 = (box2[1][0] - box2[0][0]) * (box2[1][1] - box2[0][1])\n",
    "        \n",
    "        if (min(area1, area2) == 0):\n",
    "            return 0\n",
    "\n",
    "        return overlap_area / min(area1, area2)\n",
    "\n",
    "    def merge_overlapping_words_in_paragraph(paragraph):\n",
    "        \"\"\"Merge overlapping words within a paragraph.\"\"\"\n",
    "        words = paragraph['words']\n",
    "        if not words:\n",
    "            return paragraph\n",
    "\n",
    "        merged_words = [words[0]]\n",
    "\n",
    "        for current_word in words[1:]:\n",
    "            merge_found = False\n",
    "            for i, merged_word in enumerate(merged_words):\n",
    "                cleaned_current_word = re.sub(r'[^a-zA-Z0-9-]', '', current_word['text'])\n",
    "                cleaned_merged_word = re.sub(r'[^a-zA-Z0-9-]', '', merged_word['text'])\n",
    "                \n",
    "                # Skip merging if both words are valid\n",
    "                if (cleaned_current_word != '' and cleaned_merged_word != ''):\n",
    "                    if (is_valid_word(cleaned_current_word) and is_valid_word(cleaned_merged_word)):\n",
    "                        continue\n",
    "                \n",
    "                if overlap_horizontally(merged_word['bounds'], current_word['bounds']) and on_same_line(merged_word['bounds'], current_word['bounds']):\n",
    "                    if current_word['bounds'][0][0] - merged_word['bounds'][1][0] <= word_tolerance:\n",
    "                        merged_text = merged_word['text'].strip() + current_word['text'].strip()\n",
    "                        merged_text = re.sub(r'\\s+', '', merged_text)  # Remove any remaining spaces\n",
    "                        merged_words[i] = {\n",
    "                            'text': merged_text,\n",
    "                            'bounds': merge_boxes(merged_word['bounds'], current_word['bounds'])\n",
    "                        }\n",
    "                        merge_found = True\n",
    "                        break\n",
    "            \n",
    "            if not merge_found:\n",
    "                merged_words.append(current_word)\n",
    "\n",
    "        return {\n",
    "            'text': paragraph['text'],\n",
    "            'bounds': paragraph['bounds'],\n",
    "            'words': merged_words\n",
    "        }\n",
    "    \n",
    "    # First, merge overlapping words within each paragraph\n",
    "    merged_word_paragraphs = [merge_overlapping_words_in_paragraph(p) for p in paragraphs]\n",
    "\n",
    "    # Now, merge overlapping paragraphs\n",
    "    merged_paragraphs = []\n",
    "    for paragraph in merged_word_paragraphs:\n",
    "        merge_found = False\n",
    "        for i, merged_paragraph in enumerate(merged_paragraphs):\n",
    "            overlap = calculate_overlap(merged_paragraph['bounds'], paragraph['bounds'])\n",
    "            if overlap > paragraph_overlap_threshold:\n",
    "                merged_paragraphs[i] = {\n",
    "                    'text': merged_paragraph['text'] + ' ' + paragraph['text'],\n",
    "                    'bounds': merge_boxes(merged_paragraph['bounds'], paragraph['bounds']),\n",
    "                    'words': merged_paragraph['words'] + paragraph['words']\n",
    "                }\n",
    "                merge_found = True\n",
    "                break\n",
    "        \n",
    "        if not merge_found:\n",
    "            merged_paragraphs.append(paragraph)\n",
    "\n",
    "    # Merge overlapping words again after paragraph merging\n",
    "    merged_paragraphs = merge_overlapping_words(merged_paragraphs)\n",
    "\n",
    "    # Calculate new bounds for paragraphs\n",
    "    for paragraph in merged_paragraphs:\n",
    "        paragraph['bounds'] = calculate_bounds(paragraph['words'])\n",
    "\n",
    "    return merged_paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image_path, output_path, paragraphs):\n",
    "    # Read the input image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"Image {image_path} not found.\")\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        # Draw green rectangle for paragraph bounds\n",
    "        top_left, bottom_right = paragraph['bounds']\n",
    "        cv2.rectangle(img, top_left, bottom_right, (0, 255, 0), 2)\n",
    "\n",
    "        for word in paragraph['words']:\n",
    "            # Draw blue rectangle for word bounds\n",
    "            top_left, bottom_right = word['bounds']\n",
    "            cv2.rectangle(img, top_left, bottom_right, (255, 0, 0), 1)\n",
    "\n",
    "    try:\n",
    "        # Save the image with bounding boxes\n",
    "        cv2.imwrite(output_path, img)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error saving image with bounding boxes: {e}\")\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_distance(c1, c2, rgb_margin):\n",
    "    \"\"\"Calculate if two colors are within the specified RGB margin.\"\"\"\n",
    "    return all(abs(int(a) - int(b)) <= rgb_margin for a, b in zip(c1, c2))\n",
    "\n",
    "def remove_text_from_image(image_path, paragraphs, output_path, x_padding=2, y_padding=2, rgb_margin=10):\n",
    "    # Sort paragraphs left-to-right, top-to-bottom\n",
    "    paragraphs = sorted(paragraphs, key=lambda p: p['bounds'][0][1] * 1000 + p['bounds'][0][0])\n",
    "\n",
    "    # Open the image\n",
    "    with Image.open(image_path) as img:\n",
    "        # Store original mode\n",
    "        original_mode = img.mode\n",
    "        \n",
    "        # Convert image to RGB if it's not already\n",
    "        if original_mode != 'RGB':\n",
    "            img = img.convert('RGB')\n",
    "        \n",
    "        # Convert image to numpy array for faster processing\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Iterate through paragraphs and words\n",
    "        for paragraph in paragraphs:\n",
    "            for word in paragraph['words']:\n",
    "                # Get the bounding box coordinates\n",
    "                top_left, bottom_right = word['bounds']\n",
    "                x1, y1 = top_left\n",
    "                x2, y2 = bottom_right\n",
    "                \n",
    "                # Widen the box by padding\n",
    "                x1 = max(0, x1 - x_padding)\n",
    "                y1 = max(0, y1 - y_padding)\n",
    "                x2 = min(img.width, x2 + x_padding)\n",
    "                y2 = min(img.height, y2 + y_padding)\n",
    "                \n",
    "                # Get points right outside the bounding box\n",
    "                points = [\n",
    "                    (x, y) for x in range(x1-1, x2+2) for y in [y1-1, y2+1]\n",
    "                ] + [\n",
    "                    (x, y) for y in range(y1, y2+1) for x in [x1-1, x2+1]\n",
    "                ]\n",
    "                \n",
    "                # Collect colors from these points\n",
    "                colors = [tuple(img_array[y, x]) for x, y in points if 0 <= y < img.height and 0 <= x < img.width]\n",
    "                \n",
    "                # Find the most common color considering the RGB margin\n",
    "                color_counts = Counter()\n",
    "                for color in colors:\n",
    "                    for existing_color in color_counts:\n",
    "                        if color_distance(color, existing_color, rgb_margin):\n",
    "                            color_counts[existing_color] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        color_counts[color] = 1\n",
    "                \n",
    "                counts_most_common = color_counts.most_common(1)\n",
    "                if (len(counts_most_common) == 0):\n",
    "                    most_common_color = (0, 0, 0)\n",
    "                else:\n",
    "                    most_common_color = counts_most_common[0][0]\n",
    "                \n",
    "                # Fill the bounding box with the most common color\n",
    "                img_array[y1:y2, x1:x2] = most_common_color\n",
    "        \n",
    "        # Create a new image from the modified array\n",
    "        result = Image.fromarray(img_array)\n",
    "        \n",
    "        # Convert back to original mode if necessary\n",
    "        if original_mode != 'RGB':\n",
    "            result = result.convert(original_mode)\n",
    "        \n",
    "        # Save the result\n",
    "        result.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Sectioning\n",
    "## Vertical Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vertical_lines(lines, y_merge_threshold=10, x_merge_threshold=5, overlap_only=False):\n",
    "    \"\"\"\n",
    "    Merge vertical lines that are close to each other.\n",
    "    \n",
    "    :param lines: List of lines, each represented as [x1, y1, x2, y2]\n",
    "    :param y_merge_threshold: Maximum vertical distance to consider merging non-overlapping lines\n",
    "    :param x_merge_threshold: Maximum horizontal distance to consider lines for merging\n",
    "    :param overlap_only: If True, only merge lines that vertically overlap\n",
    "    :return: Numpy array of merged lines\n",
    "    \"\"\"\n",
    "    if lines is None or len(lines) == 0:\n",
    "        return []\n",
    "\n",
    "    # Convert to numpy array and sort by x-coordinate\n",
    "    lines = np.array(lines, dtype=float)\n",
    "    sorted_indices = np.argsort(lines[:, 0])\n",
    "    sorted_lines = lines[sorted_indices]\n",
    "    \n",
    "    merged_lines = []\n",
    "    \n",
    "    while len(sorted_lines) > 0:\n",
    "        # Take the first line as the current line to merge\n",
    "        current_line = sorted_lines[0]\n",
    "        sorted_lines = sorted_lines[1:]\n",
    "        x, y1, _, y2 = current_line\n",
    "        y1, y2 = min(y1, y2), max(y1, y2)\n",
    "        \n",
    "        merged = True\n",
    "        while merged:\n",
    "            merged = False\n",
    "            # Find candidate lines within x_merge_threshold\n",
    "            mask = np.abs(sorted_lines[:, 0] - x) <= x_merge_threshold\n",
    "            candidates = sorted_lines[mask]\n",
    "            for i, line in enumerate(candidates):\n",
    "                lx, ly1, _, ly2 = line\n",
    "                ly1, ly2 = min(ly1, ly2), max(ly1, ly2)\n",
    "                \n",
    "                # Check for vertical overlap or proximity\n",
    "                y_overlap = (min(y2, ly2) - max(y1, ly1)) > 0\n",
    "                if not overlap_only:\n",
    "                    y_overlap = y_overlap or abs(y2 - ly1) <= y_merge_threshold or abs(y1 - ly2) <= y_merge_threshold\n",
    "                \n",
    "                if y_overlap:\n",
    "                    # Merge the lines\n",
    "                    x = (x + lx) / 2\n",
    "                    y1 = min(y1, ly1)\n",
    "                    y2 = max(y2, ly2)\n",
    "                    # Remove the merged line from sorted_lines\n",
    "                    sorted_lines = np.delete(sorted_lines, np.where(np.all(sorted_lines == line, axis=1))[0], axis=0)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                break\n",
    "        \n",
    "        merged_lines.append([x, y1, x, y2])\n",
    "    \n",
    "    return np.array(merged_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hough_transform(gray, img_shape, min_height_percent, threshold, max_line_gap, edge_min, edge_max):\n",
    "    \"\"\"\n",
    "    Apply Hough Transform to detect vertical lines in an image.\n",
    "\n",
    "    :param gray: Grayscale input image\n",
    "    :param img_shape: Shape of the input image\n",
    "    :param min_height_percent: Minimum line height as a percentage of image height\n",
    "    :param threshold: Threshold for line detection\n",
    "    :param max_line_gap: Maximum gap between line segments to be connected\n",
    "    :param edge_min: Lower threshold for edge detection\n",
    "    :param edge_max: Upper threshold for edge detection\n",
    "    :return: List of detected vertical lines\n",
    "    \"\"\"\n",
    "    # Apply Gabor filter to enhance vertical edges\n",
    "    kernel = cv2.getGaborKernel((21, 21), 5, 0, 10, 1, 0, ktype=cv2.CV_32F)\n",
    "    filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)\n",
    "    filtered = cv2.cvtColor(filtered, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Apply Canny edge detection\n",
    "    edges = cv2.Canny(filtered, edge_min, edge_max, apertureSize=3)\n",
    "\n",
    "    # Apply probabilistic Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold, \n",
    "                            minLineLength=int(img_shape[0]*min_height_percent), \n",
    "                            maxLineGap=max_line_gap)\n",
    "    \n",
    "    if (lines is None) or len(lines) == 0:\n",
    "        return np.array([])\n",
    "\n",
    "    cleaned_lines = []\n",
    "    # Filter out non-vertical lines\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if abs(x2 - x1) < 5:  # Consider lines with horizontal difference less than 5 pixels as vertical\n",
    "            cleaned_lines.append([x1, y1, x2, y2])\n",
    "    return cleaned_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsd_transform(gray):\n",
    "    \"\"\"\n",
    "    Apply Line Segment Detector (LSD) to detect vertical lines in an image.\n",
    "\n",
    "    :param gray: Grayscale input image\n",
    "    :return: List of detected vertical lines\n",
    "    \"\"\"\n",
    "    # Create a Line Segment Detector object\n",
    "    lsd = cv2.createLineSegmentDetector(0)\n",
    "    \n",
    "    # Detect lines in the image\n",
    "    lines = lsd.detect(gray)[0]\n",
    "    filtered_lines = []\n",
    "\n",
    "    # Check if any lines were detected\n",
    "    if (lines is None) or (len(lines) == 0):\n",
    "        return np.array(filtered_lines)\n",
    "\n",
    "    # Filter out non-vertical lines\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        if abs(x2 - x1) < 5:  # Consider lines with horizontal difference less than 5 pixels as vertical\n",
    "            filtered_lines.append([x1, y1, x2, y2])\n",
    "    \n",
    "    return filtered_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_vertical_lines(image_path, vertical_lines, output_path):\n",
    "    \"\"\"\n",
    "    Draw detected vertical lines on an image and save the result.\n",
    "\n",
    "    :param image_path: Path to the original image\n",
    "    :param vertical_lines: List of vertical lines to draw\n",
    "    :param output_path: Path to save the output image\n",
    "    \"\"\"\n",
    "    # Read the original image\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    count = 0\n",
    "    # Add the lines to the image\n",
    "    for x, y1, y2 in vertical_lines:\n",
    "        # Calculate color based on line index\n",
    "        color = (255/len(vertical_lines)*count, 0, 255-(255/len(vertical_lines)*count))\n",
    "        # Draw the line on the image\n",
    "        cv2.line(img, (int(x), int(y1)), (int(x), int(y2)), color, 2)\n",
    "        count += 1\n",
    "\n",
    "    # Save the result\n",
    "    cv2.imwrite(output_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vertical_lines(image_path, output_path, threshold=100, min_height_percent=0.3, max_line_gap=20, edge_min=50, edge_max=150):\n",
    "    \"\"\"\n",
    "    Detect and draw vertical lines on an image using both LSD and Hough transforms.\n",
    "\n",
    "    :param image_path: Path to the input image\n",
    "    :param output_path: Path to save the output image\n",
    "    :param threshold: Threshold for Hough transform\n",
    "    :param min_height_percent: Minimum line height as a percentage of image height\n",
    "    :param max_line_gap: Maximum gap between line segments to be connected\n",
    "    :param edge_min: Lower threshold for edge detection\n",
    "    :param edge_max: Upper threshold for edge detection\n",
    "    \"\"\"\n",
    "    # Read the image and convert to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    img_height, img_width, _ = img.shape\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect vertical lines using LSD transform\n",
    "    lsd_lines = lsd_transform(gray)\n",
    "    lsd_lines = merge_vertical_lines(lsd_lines, y_merge_threshold=10, x_merge_threshold=10)\n",
    "    lsd_lines = list(filter(lambda line: abs(line[1] - line[3]) > 100, lsd_lines))\n",
    "\n",
    "    # Detect vertical lines using Hough transform\n",
    "    h_lines = hough_transform(gray, img.shape, min_height_percent, threshold, max_line_gap, edge_min, edge_max)\n",
    "    h_lines = merge_vertical_lines(h_lines, y_merge_threshold=15, x_merge_threshold=15)\n",
    "\n",
    "    # Combine LSD and Hough lines\n",
    "    if (len(lsd_lines) == 0):\n",
    "        lines = h_lines\n",
    "    elif (len(h_lines) == 0):\n",
    "        lines = lsd_lines\n",
    "    else:\n",
    "        lines = np.concatenate((lsd_lines, h_lines), axis=0)\n",
    "    \n",
    "    # Merge overlapping lines\n",
    "    lines = merge_vertical_lines(lines, x_merge_threshold=20, overlap_only=True)\n",
    "\n",
    "    # Filter lines based on height and position\n",
    "    vertical_lines = []\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = map(int, line)\n",
    "            if abs(y2 - y1) < min_height_percent*img_height:\n",
    "                continue\n",
    "            if abs(x2 - x1) < 20 and x1 > 10 and x2 < img_width - 10:\n",
    "                vertical_lines.append((x1, y1, y2))\n",
    "\n",
    "    # Save the image with detected vertical lines\n",
    "    save_vertical_lines(image_path, vertical_lines, output_path)\n",
    "\n",
    "    return img, vertical_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Horizontal Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_horizontal_lines(img_path, output_path, vertical_lines):\n",
    "    \"\"\"\n",
    "    Detect horizontal lines based on detected vertical lines and draw them on the image.\n",
    "\n",
    "    :param img_path: Path to the input image\n",
    "    :param output_path: Path to save the output image\n",
    "    :param vertical_lines: List of detected vertical lines\n",
    "    :return: Tuple of (modified image, list of horizontal lines)\n",
    "    \"\"\"\n",
    "    # Read the image\n",
    "    img = cv2.imread(img_path)\n",
    "    _, img_width, _ = img.shape\n",
    "\n",
    "    # Sort vertical lines by x-coordinate\n",
    "    vertical_lines.sort(key=lambda x: x[0])\n",
    "\n",
    "    horizontal_lines = []\n",
    "\n",
    "    for i, line in enumerate(vertical_lines):\n",
    "        x, y1, y2 = line\n",
    "        \n",
    "        # Process top horizontal line (y1)\n",
    "        left_x = x\n",
    "        right_x = x\n",
    "        \n",
    "        # Find left endpoint\n",
    "        for j in range(i-1, -1, -1):\n",
    "            if vertical_lines[j][1] <= y1 <= vertical_lines[j][2]:\n",
    "                left_x = vertical_lines[j][0]\n",
    "                break\n",
    "        if left_x == x:\n",
    "            left_x = 0\n",
    "\n",
    "        # Find right endpoint\n",
    "        for j in range(i+1, len(vertical_lines)):\n",
    "            if vertical_lines[j][1] <= y1 <= vertical_lines[j][2]:\n",
    "                right_x = vertical_lines[j][0]\n",
    "                break\n",
    "        if right_x == x:\n",
    "            right_x = img_width\n",
    "        \n",
    "        # Add top horizontal line\n",
    "        horizontal_lines.append((left_x, y1, right_x, y1))\n",
    "        cv2.line(img, (left_x, y1), (right_x, y1), (0, 255, 0), 2)\n",
    "        \n",
    "        # Process bottom horizontal line (y2)\n",
    "        left_x = x\n",
    "        right_x = x\n",
    "        \n",
    "        # Find left endpoint\n",
    "        for j in range(i-1, -1, -1):\n",
    "            if vertical_lines[j][1] <= y2 <= vertical_lines[j][2]:\n",
    "                left_x = vertical_lines[j][0]\n",
    "                break\n",
    "        if left_x == x:\n",
    "            left_x = 0\n",
    "        \n",
    "        # Find right endpoint\n",
    "        for j in range(i+1, len(vertical_lines)):\n",
    "            if vertical_lines[j][1] <= y2 <= vertical_lines[j][2]:\n",
    "                right_x = vertical_lines[j][0]\n",
    "                break\n",
    "        if right_x == x:\n",
    "            right_x = img_width\n",
    "        \n",
    "        # Add bottom horizontal line\n",
    "        horizontal_lines.append((left_x, y2, right_x, y2))\n",
    "        cv2.line(img, (left_x, y2), (right_x, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Save the image with horizontal lines\n",
    "    cv2.imwrite(output_path, img)\n",
    "\n",
    "    return img, horizontal_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_adjusted_lines(folder_dir, adjusted_vertical_lines, adjusted_horizontal_lines):\n",
    "    \"\"\"\n",
    "    Save the adjusted vertical and horizontal lines on the image.\n",
    "\n",
    "    :param folder_dir: Directory to save the output images\n",
    "    :param adjusted_vertical_lines: List of adjusted vertical lines\n",
    "    :param adjusted_horizontal_lines: List of adjusted horizontal lines\n",
    "    \"\"\"\n",
    "    # Save vertical lines\n",
    "    new_lines_path = f\"{folder_dir}/new_vertical_lines.png\"\n",
    "    save_vertical_lines(f\"{folder_dir}/merged_removed.png\", adjusted_vertical_lines, new_lines_path)\n",
    "\n",
    "    # Read the image with vertical lines\n",
    "    img = cv2.imread(new_lines_path)\n",
    "\n",
    "    # Add horizontal lines to the image\n",
    "    for line in adjusted_horizontal_lines:\n",
    "        cv2.line(img, (line[0], line[1]), (line[2], line[1]), (255, 255, 0), 2)\n",
    "\n",
    "    # Save the image with both vertical and horizontal lines\n",
    "    cv2.imwrite(f\"{folder_dir}/new_horizontal_lines.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_lines(folder_dir, vertical_lines, horizontal_lines, img_width, img_height, min_height):\n",
    "    \"\"\"\n",
    "    Adjust and merge detected lines to create a more coherent grid structure.\n",
    "\n",
    "    :param folder_dir: Directory to save output images\n",
    "    :param vertical_lines: List of detected vertical lines\n",
    "    :param horizontal_lines: List of detected horizontal lines\n",
    "    :param img_width: Width of the image\n",
    "    :param img_height: Height of the image\n",
    "    :param min_height: Minimum height threshold for merging lines\n",
    "    :return: Tuple of adjusted vertical and horizontal lines\n",
    "    \"\"\"\n",
    "    # Add the top and bottom of the image as horizontal lines\n",
    "    horizontal_lines.append((0, 0, img_width, 0))\n",
    "    horizontal_lines.append((0, img_height, img_width, img_height))\n",
    "\n",
    "    # Sort horizontal lines by y-coordinate\n",
    "    horizontal_lines.sort(key=lambda x: x[1])\n",
    "\n",
    "    # Merge close horizontal lines\n",
    "    adjusted_horizontal_lines = [horizontal_lines[0]]\n",
    "    for i in range(1, len(horizontal_lines)):\n",
    "        prev_line = adjusted_horizontal_lines[-1]\n",
    "        curr_line = horizontal_lines[i]\n",
    "        if abs(prev_line[1] - curr_line[1]) < min_height:\n",
    "            # Merge lines if they are close\n",
    "            adjusted_horizontal_lines[-1] = (\n",
    "                min(prev_line[0], curr_line[0]),\n",
    "                int((prev_line[1] + curr_line[1])/2),\n",
    "                max(prev_line[2], curr_line[2]),\n",
    "                0\n",
    "            )\n",
    "        else:\n",
    "            adjusted_horizontal_lines.append(curr_line)\n",
    "\n",
    "    # Adjust vertical lines based on new horizontal lines\n",
    "    adjusted_vertical_lines = []\n",
    "    for v_line in vertical_lines:\n",
    "        v_x, v_y1, v_y2 = v_line[0], min(v_line[1], v_line[2]), max(v_line[1], v_line[2])\n",
    "        for h_line in adjusted_horizontal_lines:\n",
    "            if abs(h_line[1] - v_y1) < min_height:\n",
    "                v_y1 = h_line[1]\n",
    "            if abs(h_line[1] - v_y2) < min_height:\n",
    "                v_y2 = h_line[1]\n",
    "        adjusted_vertical_lines.append((v_x, v_y1, v_y2))\n",
    "\n",
    "    # Save the adjusted lines\n",
    "    save_adjusted_lines(folder_dir, adjusted_vertical_lines, adjusted_horizontal_lines)\n",
    "    \n",
    "    return adjusted_vertical_lines, adjusted_horizontal_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rectangular_sections(folder_dir, vertical_lines, horizontal_lines, img_width, img_height, min_width=10, min_height=10):\n",
    "    \"\"\"\n",
    "    Create rectangular sections based on detected vertical and horizontal lines.\n",
    "\n",
    "    :param folder_dir: Directory to save output images\n",
    "    :param vertical_lines: List of detected vertical lines\n",
    "    :param horizontal_lines: List of detected horizontal lines\n",
    "    :param img_width: Width of the image\n",
    "    :param img_height: Height of the image\n",
    "    :param min_width: Minimum width for a valid section\n",
    "    :param min_height: Minimum height for a valid section\n",
    "    :return: List of rectangular sections\n",
    "    \"\"\"\n",
    "    sections = []\n",
    "\n",
    "    # Adjust lines to create a more coherent grid structure\n",
    "    adjusted_vertical_lines, adjusted_horizontal_lines = adjust_lines(folder_dir, vertical_lines, horizontal_lines, img_width, img_height, min_height)\n",
    "\n",
    "    # Create initial rectangles spanning the entire image width\n",
    "    for i in range(len(adjusted_horizontal_lines) - 1):\n",
    "        y1 = adjusted_horizontal_lines[i][1]\n",
    "        y2 = adjusted_horizontal_lines[i + 1][1]\n",
    "        if y2 - y1 >= min_height:\n",
    "            sections.append((0, y1, img_width, y2))\n",
    "\n",
    "    # Split rectangles that collide with vertical lines\n",
    "    for v_line in adjusted_vertical_lines:\n",
    "        v_x, v_y1, v_y2 = v_line\n",
    "        new_sections = []\n",
    "        narrow_sections = []\n",
    "\n",
    "        for section in sections:\n",
    "            x1, y1, x2, y2 = section\n",
    "            if x1 < v_x < x2 and y1 < v_y2 and v_y1 < y2:\n",
    "                # Split the section if it intersects with the vertical line\n",
    "                if v_x - x1 >= min_width:\n",
    "                    new_sections.append((x1, y1, v_x, y2))\n",
    "                else:\n",
    "                    narrow_sections.append((x1, y1, v_x, y2))\n",
    "                if x2 - v_x >= min_width:\n",
    "                    new_sections.append((v_x, y1, x2, y2))\n",
    "                else:\n",
    "                    narrow_sections.append((v_x, y1, x2, y2))\n",
    "            else:\n",
    "                new_sections.append(section)\n",
    "\n",
    "        sections = new_sections\n",
    "\n",
    "        # Merge narrow sections with the next big enough section\n",
    "        for narrow_section in narrow_sections:\n",
    "            x1, y1, x2, y2 = narrow_section\n",
    "            merged = False\n",
    "            for i in range(len(sections)):\n",
    "                sx1, sy1, sx2, sy2 = sections[i]\n",
    "                if y1 == sy1 and y2 == sy2 and sx1 == x2:\n",
    "                    sections[i] = (x1, y1, sx2, y2)\n",
    "                    merged = True\n",
    "                    break\n",
    "            if not merged:\n",
    "                sections.append(narrow_section)\n",
    "\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vertical_rectangles(sections, horizontal_lines, min_height=10):\n",
    "    \"\"\"\n",
    "    Merge vertically adjacent rectangles that have the same width and no horizontal line between them.\n",
    "\n",
    "    :param sections: List of rectangular sections, each represented as (x1, y1, x2, y2)\n",
    "    :param horizontal_lines: List of horizontal lines, each represented as (x1, y1, x2, y2)\n",
    "    :param min_height: Minimum height for a valid section\n",
    "    :return: List of merged rectangular sections\n",
    "    \"\"\"\n",
    "    merged_sections = []\n",
    "    sections.sort(key=lambda x: (x[0], x[1]))  # Sort by x, then y\n",
    "\n",
    "    i = 0\n",
    "    while i < len(sections):\n",
    "        current = sections[i]\n",
    "        j = i + 1\n",
    "        while j < len(sections):\n",
    "            next_section = sections[j]\n",
    "            \n",
    "            # Check if sections are vertically adjacent and have the same width\n",
    "            if (current[0] == next_section[0] and \n",
    "                current[2] == next_section[2] and \n",
    "                current[3] == next_section[1]):\n",
    "                \n",
    "                # Check if there's no horizontal line between them\n",
    "                if not any(h_line[1] == current[3] and \n",
    "                           h_line[0] <= current[0] < current[2] <= h_line[2] \n",
    "                           for h_line in horizontal_lines):\n",
    "                    \n",
    "                    # Merge the sections\n",
    "                    current = (current[0], current[1], current[2], next_section[3])\n",
    "                    j += 1\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        # Add the merged section if it meets the minimum height requirement\n",
    "        if current[3] - current[1] >= min_height:\n",
    "            merged_sections.append(current)\n",
    "        i = j\n",
    "\n",
    "    return merged_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_debug_sections(img_path, output_path, merged_sections):\n",
    "    \"\"\"\n",
    "    Create and save a debug image showing the merged sections with colors and indices.\n",
    "\n",
    "    :param img_path: Path to the original image\n",
    "    :param output_path: Path to save the debug image\n",
    "    :param merged_sections: List of merged rectangular sections\n",
    "    \"\"\"\n",
    "    # Read the original image\n",
    "    debug_img = cv2.imread(img_path)\n",
    "\n",
    "    # Generate a list of distinct random colors for each section\n",
    "    colors = [(np.random.randint(0, 255), np.random.randint(0, 255), np.random.randint(0, 255)) for _ in range(len(merged_sections))]\n",
    "\n",
    "    # Draw the sections with index and color\n",
    "    for i, section in enumerate(merged_sections):\n",
    "        x1, y1, x2, y2 = section\n",
    "        color = colors[i]\n",
    "        \n",
    "        # Draw the rectangle outline\n",
    "        cv2.rectangle(debug_img, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        # Add the index number\n",
    "        cv2.putText(debug_img, str(i), (x1 + 5, y1 + 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "        \n",
    "        # Fill the section with a semi-transparent color\n",
    "        overlay = debug_img.copy()\n",
    "        cv2.rectangle(overlay, (x1, y1), (x2, y2), color, -1)\n",
    "        cv2.addWeighted(overlay, 0.2, debug_img, 0.8, 0, debug_img)\n",
    "\n",
    "    # Save the debug image\n",
    "    cv2.imwrite(output_path, debug_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Layout and Formatting\n",
    "## Text Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_sort_key(word, line_height, tolerance=0):\n",
    "    \"\"\"\n",
    "    Generate a sorting key for a word based on its position in the document.\n",
    "\n",
    "    :param word: Dictionary containing word information, including 'bounds'\n",
    "    :param line_height: Height of a line in the document\n",
    "    :param tolerance: Tolerance value for line number calculation\n",
    "    :return: Tuple (line_number, x) for sorting\n",
    "    \"\"\"\n",
    "    x, y = word['bounds'][0]  # Extract x and y coordinates of the word's top-left corner\n",
    "    line_number = (y + tolerance) // line_height  # Calculate the line number\n",
    "    return (line_number, x)  # Return a tuple for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_section(word_center_x, word_center_y, sections):\n",
    "    \"\"\"\n",
    "    Find the section that contains a given word based on its center coordinates.\n",
    "\n",
    "    :param word_center_x: X-coordinate of the word's center\n",
    "    :param word_center_y: Y-coordinate of the word's center\n",
    "    :param sections: List of sections, each represented as (x1, y1, x2, y2)\n",
    "    :return: Index of the containing section, or -1 if not found\n",
    "    \"\"\"\n",
    "    for i, section in enumerate(sections):\n",
    "        # Check if the word's center is within the current section's boundaries\n",
    "        if (section[0] <= word_center_x <= section[2] and \n",
    "            section[1] <= word_center_y <= section[3]):\n",
    "            return i\n",
    "    \n",
    "    # If no containing section is found, return -1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_paragraph(paragraph, sections):\n",
    "    \"\"\"\n",
    "    Split a paragraph into multiple paragraphs based on the sections it spans.\n",
    "\n",
    "    :param paragraph: Dictionary containing paragraph information, including 'words'\n",
    "    :param sections: List of sections, each represented as (x1, y1, x2, y2)\n",
    "    :return: List of split paragraphs, each associated with a section\n",
    "    \"\"\"\n",
    "    # Initialize a list of empty paragraphs, one for each section\n",
    "    split_paragraphs = [{'words': [], 'section': i, 'bounds': list(section)} for i, section in enumerate(sections)]\n",
    "    \n",
    "    for word in paragraph['words']:\n",
    "        # Calculate the center of the word\n",
    "        word_center = ((word['bounds'][0][0] + word['bounds'][1][0]) / 2, \n",
    "                       (word['bounds'][0][1] + word['bounds'][1][1]) / 2)\n",
    "        \n",
    "        # Find which section the word belongs to\n",
    "        sec_id = find_section(word_center[0], word_center[1], sections)\n",
    "        if sec_id != -1:\n",
    "            # Add the word to the appropriate section's paragraph\n",
    "            split_paragraphs[sec_id]['words'].append(word)\n",
    "    \n",
    "    # Return only the paragraphs that contain words\n",
    "    return [p for p in split_paragraphs if p['words']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_words_with_layout(words, section_bounds, use_relative_tabs, use_ascii_only, line_height=10):\n",
    "    \"\"\"\n",
    "    Format words with layout information, preserving spatial relationships.\n",
    "\n",
    "    :param words: List of word dictionaries containing text and position information\n",
    "    :param section_bounds: Boundaries of the section (x1, y1, x2, y2)\n",
    "    :param use_relative_tabs: Boolean to determine if relative tabbing should be used\n",
    "    :param use_ascii_only: Boolean to filter out non-ASCII characters\n",
    "    :param line_height: Height of a line for determining line breaks\n",
    "    :return: Formatted text string\n",
    "    \"\"\"\n",
    "    words = deepcopy(words)  # Create a deep copy to avoid modifying the original\n",
    "\n",
    "    formatted_text = \"\"\n",
    "    section_start_x, section_start_y = section_bounds[0], section_bounds[1]\n",
    "    prev_y = section_start_y\n",
    "    last_x = section_start_x\n",
    "    \n",
    "    # Calculate average character width for tabbing\n",
    "    avg_char_width = sum(len(word['text']) for word in words) / max(1, len(words))\n",
    "    tab_width = 15 * avg_char_width\n",
    "    \n",
    "    count = 0\n",
    "    for word in words:\n",
    "        if use_ascii_only:\n",
    "            word['text'] = ''.join(c for c in word['text'] if ord(c) < 128)\n",
    "    \n",
    "        if not word['text']:\n",
    "            continue\n",
    "\n",
    "        current_x, current_y = word['bounds'][0]\n",
    "        vertical_distance = current_y - prev_y        \n",
    "\n",
    "        # Handle line breaks\n",
    "        if vertical_distance > line_height * 0.75:\n",
    "            formatted_text += \"\\n\"\n",
    "            if vertical_distance > line_height * 2.5:\n",
    "                formatted_text += \"\\n\"  # Extra line break for larger gaps\n",
    "            last_x = section_start_x\n",
    "            \n",
    "            # Add tabs at the start of the line\n",
    "            initial_tabs = max(0, min(int((current_x - section_start_x) / tab_width), 8))\n",
    "            if initial_tabs > 0:\n",
    "                formatted_text += \"\\t\" * int(initial_tabs / 2)\n",
    "\n",
    "        if count == 0:\n",
    "            # Add tabs at the start of the first line\n",
    "            initial_tabs = max(0, min(int((current_x - section_start_x) / tab_width), 8))\n",
    "            if initial_tabs > 0:\n",
    "                formatted_text += \"\\t\" * int(initial_tabs / 2)\n",
    "            count += 1\n",
    "        \n",
    "        elif use_relative_tabs:\n",
    "            # Add tabs within the same line\n",
    "            horizontal_distance = current_x - last_x\n",
    "            horizontal_tabs = max(0, min(int(horizontal_distance / tab_width / 2), 4))\n",
    "            if horizontal_tabs > 0:\n",
    "                formatted_text += \"\\t\" * horizontal_tabs\n",
    "            elif formatted_text and formatted_text[-1] != \"\\n\":\n",
    "                formatted_text += \" \"\n",
    "        else:\n",
    "            # Add a space if not at the beginning of a line\n",
    "            if formatted_text and formatted_text[-1] != \"\\n\":\n",
    "                formatted_text += \" \"\n",
    "\n",
    "        formatted_text += word['text']\n",
    "\n",
    "        prev_y = current_y\n",
    "        last_x = current_x + len(word['text']) * avg_char_width\n",
    "\n",
    "    return formatted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text in Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_text_in_sections(merged_sections, merged_paragraphs, use_ascii_only=False, use_relative_tabs=False):\n",
    "    # Flatten all words from all paragraphs into a single list\n",
    "    words = [word for paragraph in merged_paragraphs for word in paragraph['words']]\n",
    "\n",
    "    # If no words are found, return an empty list\n",
    "    if not words:\n",
    "        return []\n",
    "    \n",
    "    # Calculate the most common line height from word bounding boxes\n",
    "    line_heights = [word['bounds'][1][1] - word['bounds'][0][1] for word in words]\n",
    "    line_height = max(set(line_heights), key=line_heights.count)\n",
    "\n",
    "    # Split paragraphs that span multiple sections\n",
    "    new_paragraphs = []\n",
    "    for paragraph in merged_paragraphs:\n",
    "        split_paragraphs = split_paragraph(paragraph, merged_sections)\n",
    "        new_paragraphs.extend(split_paragraphs)\n",
    "\n",
    "    section_data = []\n",
    "    for i, section in enumerate(merged_sections):\n",
    "        # Collect paragraphs and words for the current section\n",
    "        section_paragraphs = [p for p in new_paragraphs if p['section'] == i]\n",
    "        all_words = [word for paragraph in section_paragraphs for word in paragraph['words']]\n",
    "        if not all_words:\n",
    "            continue\n",
    "\n",
    "        # Sort words within the section\n",
    "        sorted_words = sorted(all_words, key=lambda w: word_sort_key(w, line_height))\n",
    "        \n",
    "        # Format the text for the section\n",
    "        formatted_text = format_words_with_layout(sorted_words, section, use_relative_tabs, use_ascii_only, line_height)\n",
    "        section_data.append({\"words\": sorted_words, \"text\": formatted_text})\n",
    "\n",
    "    return section_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_text(folder_output_dir, file_name, text):\n",
    "    # Open a file for writing in the specified output directory\n",
    "    with open(f\"{folder_output_dir}/{file_name}.txt\", 'w') as f:\n",
    "        # Iterate through each section in the text\n",
    "        for i, section in enumerate(text):\n",
    "            f.write(f\"Section {i}:\\n\")\n",
    "            f.write(section)\n",
    "            f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_ocr_sections(folder_output_dir, merged_sections, merged_paragraphs):\n",
    "    #? Format text in sections\n",
    "    # Process sections without ASCII filtering or relative tabs\n",
    "    sections = format_text_in_sections(merged_sections, merged_paragraphs, use_ascii_only=False)\n",
    "    sections_text = [section['text'] for section in sections]\n",
    "    save_text(folder_output_dir, \"processed_text\", sections_text)\n",
    "\n",
    "    # Save the number of sections\n",
    "    with open(f\"{folder_output_dir}/section_count.txt\", 'w') as f:\n",
    "        f.write(f\"Number of sections: {len(sections)}\")\n",
    "\n",
    "    # Process sections with relative tabs but without ASCII filtering\n",
    "    sections_tabs = format_text_in_sections(merged_sections, merged_paragraphs, use_relative_tabs=True, use_ascii_only=False)\n",
    "    sections_text_tabs = [section['text'] for section in sections_tabs]\n",
    "    save_text(folder_output_dir, \"processed_text_tabs\", sections_text_tabs)\n",
    "\n",
    "    #? Format text in sections with ASCII only\n",
    "    # Process sections with ASCII filtering\n",
    "    ascii_section = format_text_in_sections(merged_sections, merged_paragraphs, use_ascii_only=True)\n",
    "    ascii_section_text = [section['text'] for section in ascii_section]\n",
    "    save_text(folder_output_dir, \"processed_text_ascii\", ascii_section_text)\n",
    "\n",
    "    #! RETURNING THE TEXT, WITH ONLY INITIAL TABS AND WITH CHARACTERS OUTSIDE ASCII\n",
    "    return sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Not used) Line Number Detection and Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_number(text):\n",
    "    # Dictionary for special number characters\n",
    "    special_numbers = {'①': '1', '②': '2', '③': '3', '④': '4', '⑤': '5',\n",
    "                       '⑥': '6', '⑦': '7', '⑧': '8', '⑨': '9'}\n",
    "    \n",
    "    # Check if the text is a special number character\n",
    "    if text in special_numbers:\n",
    "        return True, int(special_numbers[text])\n",
    "    \n",
    "    # Extract all standard digits from the text\n",
    "    digits = ''.join(char for char in text if char in '0123456789')\n",
    "    \n",
    "    # Check if there are any standard digits\n",
    "    if not digits:\n",
    "        return False, None\n",
    "    \n",
    "    # Remove standard digits from the original text\n",
    "    non_digits = ''.join(char for char in text if char not in '0123456789')\n",
    "    \n",
    "    # Check if there's at most one non-digit character left\n",
    "    # This allows for numbers with a single prefix or suffix character\n",
    "    if len(non_digits) <= 1:\n",
    "        return True, int(digits)\n",
    "    \n",
    "    # If more than one non-digit character remains, it's not a valid number\n",
    "    return False, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_line_numbers(paragraphs, horizontal_threshold=50, vertical_threshold=50, min_consecutive=3):\n",
    "    # Initialize a defaultdict to store numbers and their corresponding words\n",
    "    number_dict = defaultdict(list)\n",
    "\n",
    "    # Flatten the list of words from all paragraphs\n",
    "    words = [word.copy() for paragraph in paragraphs for word in paragraph['words']]\n",
    "    \n",
    "    # First pass: group numbers\n",
    "    for word in words:\n",
    "        number_test = is_valid_number(word['text'])\n",
    "        if number_test[0]:\n",
    "            word['text'] = number_test[1]\n",
    "            number_dict[number_test[1]].append(word)\n",
    "    \n",
    "    valid_sequences = []\n",
    "    current_sequence = []\n",
    "    \n",
    "    # Iterate through sorted numbers to find consecutive sequences\n",
    "    for number in sorted(number_dict.keys()):\n",
    "        if not current_sequence:\n",
    "            current_sequence.append(number_dict[number][0])\n",
    "            continue\n",
    "        \n",
    "        prev_word = current_sequence[-1]\n",
    "        \n",
    "        if number == int(prev_word['text']) + 1:\n",
    "            # Find the best aligned occurrence of the current number\n",
    "            best_word = min(number_dict[number], key=lambda w: (\n",
    "                abs(w['bounds'][0][0] - prev_word['bounds'][0][0]),  # x difference\n",
    "                w['bounds'][0][1] - prev_word['bounds'][0][1]  # y difference\n",
    "            ))\n",
    "            \n",
    "            # Check if the best occurrence is within horizontal and vertical thresholds\n",
    "            if (abs(best_word['bounds'][0][0] - prev_word['bounds'][0][0]) <= horizontal_threshold and\n",
    "                0 < best_word['bounds'][0][1] - prev_word['bounds'][0][1] <= vertical_threshold):\n",
    "                current_sequence.append(best_word)\n",
    "            else:\n",
    "                # Not aligned or too far apart vertically, start a new sequence\n",
    "                if len(current_sequence) >= min_consecutive:\n",
    "                    valid_sequences.append(current_sequence)\n",
    "                current_sequence = [best_word]\n",
    "        else:\n",
    "            # Not consecutive, start a new sequence\n",
    "            if len(current_sequence) >= min_consecutive:\n",
    "                valid_sequences.append(current_sequence)\n",
    "            current_sequence = [number_dict[number][0]]\n",
    "    \n",
    "    # Check the last sequence\n",
    "    if len(current_sequence) >= min_consecutive:\n",
    "        valid_sequences.append(current_sequence)\n",
    "    \n",
    "    expanded_sequences = []\n",
    "    # Add words on the same vertical line for each sequence\n",
    "    for sequence in valid_sequences:\n",
    "        new_sequence = sequence.copy()\n",
    "        x_coord = sequence[0]['bounds'][1][0]\n",
    "        for number in number_dict:\n",
    "            for word in number_dict[number]:\n",
    "                if abs(word['bounds'][1][0] - x_coord) <= horizontal_threshold and word not in sequence:\n",
    "                    new_sequence.append(word)\n",
    "        sequence.sort(key=lambda w: w['bounds'][0][1])  # Sort by y-coordinate\n",
    "        expanded_sequences.append(new_sequence)\n",
    "\n",
    "    return expanded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_line_numbers(paragraphs, number_sequence):\n",
    "    # Create a deep copy of paragraphs to avoid modifying the original\n",
    "    paragraphs = deepcopy(paragraphs)\n",
    "    \n",
    "    # Create a set of tuples (text, bounds) for quick lookup of numbers to remove\n",
    "    numbers_to_remove = set((str(word['text']), tuple(word['bounds'])) for word in number_sequence)\n",
    "\n",
    "    removed_count = 0\n",
    "    for paragraph in paragraphs:\n",
    "        if isinstance(paragraph, dict) and 'words' in paragraph:\n",
    "            original_words = paragraph['words']\n",
    "            paragraph['words'] = []\n",
    "            for word in original_words:\n",
    "                if (word['text'], tuple(word['bounds'])) in numbers_to_remove:\n",
    "                    removed_count += 1\n",
    "                else:\n",
    "                    paragraph['words'].append(word)\n",
    "    \n",
    "    # Remove empty paragraphs and recalculate bounds\n",
    "    paragraphs = [paragraph for paragraph in paragraphs if paragraph['words']]\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph['bounds'] = calculate_bounds(paragraph['words'])\n",
    "\n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Highlighting and Citation\n",
    "## Flexible OCR Text Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "class FlexibleOCRTextMatcher:\n",
    "    def __init__(self, pattern, threshold=0.7, case_sensitive=False):\n",
    "        # Initialize the matcher with a pattern, similarity threshold, and case sensitivity option\n",
    "        self.original_pattern = pattern\n",
    "        self.pattern = self._preprocess_text(pattern, case_sensitive)\n",
    "        self.threshold = threshold\n",
    "        self.case_sensitive = case_sensitive\n",
    "\n",
    "    def _preprocess_text(self, text, case_sensitive):\n",
    "        # Preprocess text by removing extra whitespace and optionally converting to lowercase\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        return text if case_sensitive else text.lower()\n",
    "\n",
    "    def _calculate_similarity(self, s1, s2):\n",
    "        # Calculate similarity between two strings\n",
    "        offset = 0\n",
    "        if (s1 in s2):\n",
    "            offset = 0.05\n",
    "        \n",
    "        # Use SequenceMatcher for similarity calculation\n",
    "        return min(1.0, SequenceMatcher(None, s1, s2).ratio() + offset)\n",
    "\n",
    "    def find_fuzzy_matches(self, ordered_words_section):\n",
    "        matches = []\n",
    "        # Flatten the list of words from all sections\n",
    "        all_words = [word for section in ordered_words_section for word in section['words']]\n",
    "        \n",
    "        # Iterate through all possible word combinations\n",
    "        for i in range(len(all_words)):\n",
    "            for j in range(i + 1, len(all_words) + 1):\n",
    "                original_text = ' '.join(word['text'] for word in all_words[i:j])\n",
    "                preprocessed_text = self._preprocess_text(original_text, self.case_sensitive)\n",
    "                \n",
    "                if preprocessed_text == self.pattern:\n",
    "                    # Exact match found, return immediately\n",
    "                    return [(i, original_text.strip(), 1.0, all_words[i:j])]\n",
    "                \n",
    "                similarity = self._calculate_similarity(self.pattern, preprocessed_text)\n",
    "                \n",
    "                if similarity >= self.threshold:\n",
    "                    matches.append((i, original_text.strip(), similarity, all_words[i:j]))\n",
    "\n",
    "        # Sort matches by similarity (descending) and length (ascending)\n",
    "        matches.sort(key=lambda x: (-x[2], len(x[1])))\n",
    "        \n",
    "        # Remove duplicates and near-duplicates\n",
    "        unique_matches = []\n",
    "        for match in matches:\n",
    "            if not any(self._is_similar_match(match, existing) for existing in unique_matches):\n",
    "                unique_matches.append(match)\n",
    "\n",
    "        return unique_matches\n",
    "\n",
    "    def _is_similar_match(self, match1, match2, similarity_threshold=0.95):\n",
    "        # Check if two matches are similar based on a high similarity threshold\n",
    "        text1 = self._preprocess_text(match1[1], self.case_sensitive)\n",
    "        text2 = self._preprocess_text(match2[1], self.case_sensitive)\n",
    "        return self._calculate_similarity(text1, text2) > similarity_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlighting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_words(img, matches, highlight_color=(255, 0, 0)):\n",
    "  draw = ImageDraw.Draw(img)\n",
    "  \n",
    "  for match in matches:\n",
    "      # The list of matched word dictionaries\n",
    "      matched_words = match[3]  \n",
    "      for word in matched_words:\n",
    "          top_left, bottom_right = word['bounds']\n",
    "          x1, y1 = top_left\n",
    "          x2, y2 = bottom_right\n",
    "\n",
    "          # Add a little padding around the word\n",
    "          x1 = max(0, x1 - 2)\n",
    "          y1 = max(0, y1 - 2)\n",
    "          y2 = min(img.height, y2 + 2)\n",
    "          x2 = min(img.width, x2 + 2)\n",
    "          \n",
    "          # Draw a rectangle border around the word\n",
    "          draw.rectangle([x1, y1, x2, y2], outline=highlight_color, width=2)\n",
    "  \n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_citation(citation):\n",
    "    # Remove leading/trailing whitespace and single quotes from a citation\n",
    "    return citation.strip().strip(\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_response(img_id, so_question, response, accepted_answer, ordered_words_section, img_path, folder_output_dir):\n",
    "    # Clean each citation in the parsed list\n",
    "    citations = [clean_citation(str(cite)) for cite in response['citations']]\n",
    "    explanation = response['explanation']\n",
    "\n",
    "    all_matches = []\n",
    "    citation_matches = []\n",
    "\n",
    "    # Find fuzzy matches for each citation in the OCR text\n",
    "    for citation in citations:\n",
    "        recognizer = FlexibleOCRTextMatcher(citation, threshold=0.7)\n",
    "        matches = recognizer.find_fuzzy_matches(ordered_words_section)\n",
    "\n",
    "        if matches:\n",
    "            # Get the best matches (highest similarity)\n",
    "            max_similarity = max(match[2] for match in matches)\n",
    "            best_matches = [match for match in matches if match[2] == max_similarity]\n",
    "            all_matches.extend(best_matches)\n",
    "            \n",
    "            # Store information about each match\n",
    "            for match in best_matches:\n",
    "                citation_matches.append({\n",
    "                    'citation': citation,\n",
    "                    'match_text': match[1],\n",
    "                    'similarity': match[2]\n",
    "                })\n",
    "                print(f\"Match for '{citation}': '{match[1]}' (Similarity: {match[2]:.2f})\")\n",
    "\n",
    "    # Create DataFrame with all relevant information\n",
    "    df = pd.DataFrame({\n",
    "        'id': [img_id],\n",
    "        'question': [so_question],\n",
    "        'accepted_answer': [accepted_answer],\n",
    "        'response': [explanation],\n",
    "        'citations': [citations],\n",
    "        'citation_matches': [citation_matches]\n",
    "    })\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(f\"{folder_output_dir}/citations.csv\", index=False)\n",
    "\n",
    "    # Open the image and highlight matches or create a black image if no matches\n",
    "    with Image.open(img_path) as img:\n",
    "        if all_matches:\n",
    "            highlighted_img = highlight_words(img, all_matches)\n",
    "            output_path = f\"{folder_output_dir}/citation_highlighted.png\"\n",
    "            highlighted_img.save(output_path)\n",
    "        else:\n",
    "            black_img = Image.new('RGB', img.size, (0, 0, 0))\n",
    "            output_path = f\"{folder_output_dir}/citation_highlighted.png\"\n",
    "            black_img.save(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Processing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(row_content, img_dir, output_dir, project_id):\n",
    "    MAX_RETRIES = 2\n",
    "    RETRY_DELAY = 3  # seconds\n",
    "\n",
    "    folder_output_dir = f\"{output_dir}/{row_content['id']}\"\n",
    "    img_path = f\"{img_dir}/{row_content['image_name']}\"\n",
    "    input_path = f\"{folder_output_dir}/input.png\"\n",
    "\n",
    "    print(f\"Processing image {row_content['id']}\")\n",
    "\n",
    "    # If the directory exists and contains 17 files, skip the image\n",
    "    if os.path.exists(folder_output_dir) and len(os.listdir(folder_output_dir)) == -1:\n",
    "        print(f\"Skipping image {row_content['id']}\")\n",
    "        return 2, 0  # Return status code and 0 sections\n",
    "\n",
    "    try:\n",
    "        with io.open(img_path, \"rb\") as image_file:\n",
    "            content = image_file.read()\n",
    "        VISION_image = vision.Image(content=content)\n",
    "    except Exception as e:\n",
    "        return 1, 0  # Return error status and 0 sections\n",
    "\n",
    "    # Make the directory if it doesn't exist\n",
    "    if not os.path.exists(folder_output_dir):\n",
    "        os.makedirs(folder_output_dir)\n",
    "\n",
    "    paragraphs = detect_text(VISION_image, project_id)\n",
    "    print(\"Text detection completed\")\n",
    "    \n",
    "    # Get the text, append with a \" \" for same paragraph, \"\\n\" for new paragraph\n",
    "    text = \"\"\n",
    "    for paragraph in paragraphs:\n",
    "        text += paragraph['text'] + '\\n'\n",
    "\n",
    "    # Save to file\n",
    "    with open(f\"{folder_output_dir}/unprocessed_text.txt\", 'w') as f:\n",
    "        f.write(text)\n",
    "    print(\"Unprocessed text saved\")\n",
    "\n",
    "    # Save the image, if it can't be saved, skip the image\n",
    "    try:\n",
    "        image = Image.open(img_path)\n",
    "        image.save(input_path)\n",
    "    except Exception as e:\n",
    "        return 1, 0  # Return error status and 0 sections\n",
    "\n",
    "    merged_paragraphs = merge_overlapping_paragraphs(paragraphs, word_tolerance=3, paragraph_overlap_threshold=0.5)\n",
    "    print(\"Paragraphs merged\")\n",
    "    \n",
    "    # Draw bounding boxes\n",
    "    output_path = f\"{folder_output_dir}/highlighted.png\"\n",
    "    try:\n",
    "        draw_bounding_boxes(img_path, output_path, paragraphs)\n",
    "    except Exception as e:\n",
    "        shutil.rmtree(folder_output_dir)\n",
    "        return 1, 0  # Return error status and 0 sections\n",
    "\n",
    "    output_path = f\"{folder_output_dir}/merged_highlighted.png\"\n",
    "    draw_bounding_boxes(img_path, output_path, merged_paragraphs)\n",
    "    print(\"Bounding boxes drawn\")\n",
    "\n",
    "    # Text removal\n",
    "    output_path = f\"{folder_output_dir}/removed.png\"\n",
    "    remove_text_from_image(img_path, paragraphs, output_path, x_padding=1, y_padding=1)\n",
    "    \n",
    "    removed_text_path = f\"{folder_output_dir}/merged_removed.png\"\n",
    "    remove_text_from_image(img_path, merged_paragraphs, removed_text_path, x_padding=1, y_padding=1)\n",
    "    print(\"Text removed from image\")\n",
    "\n",
    "    # Add vertical lines\n",
    "    vertical_lines_path = f\"{folder_output_dir}/detected_vertical_lines.png\"\n",
    "    img, detected_lines = add_vertical_lines(removed_text_path, vertical_lines_path, 100, 0.35, 20, 20, 200)\n",
    "\n",
    "    # Plot horizontal lines\n",
    "    output_path = f\"{folder_output_dir}/detected_horizontal_lines.png\"\n",
    "    img, horizontal_lines = get_horizontal_lines(vertical_lines_path, output_path, detected_lines)\n",
    "    print(\"Vertical and horizontal lines detected\")\n",
    "\n",
    "    # Create rectangular sections\n",
    "    img_height, img_width, _ = img.shape\n",
    "    min_width = 40; min_height = 15\n",
    "    rectangular_sections = create_rectangular_sections(folder_output_dir, detected_lines, horizontal_lines, img_width, img_height, min_width, min_height)\n",
    "    \n",
    "    # Merge vertical rectangles\n",
    "    merged_sections = merge_vertical_rectangles(rectangular_sections, horizontal_lines, min_height)\n",
    "    merged_sections.sort(key=lambda x: x[1])\n",
    "\n",
    "    output_path = f\"{folder_output_dir}/debug_sections.png\"\n",
    "    save_debug_sections(input_path, output_path, merged_sections)\n",
    "    print(\"Sections created and merged\")\n",
    "\n",
    "    # Return success status and number of sections\n",
    "    return 0, len(merged_sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main processing loop with CSV updates\n",
    "import pandas as pd\n",
    "\n",
    "def process_images_and_update_csv(df, img_dir, output_dir, project_id):\n",
    "    # Create a new column for number of sections if it doesn't exist\n",
    "    if 'num_sections' not in df.columns:\n",
    "        df['num_sections'] = 0\n",
    "    \n",
    "    # Process each image and update the DataFrame\n",
    "    for i, row in df.iterrows():\n",
    "        status_code, num_sections = process_image(row, img_dir, output_dir, project_id)\n",
    "        if status_code == 0:  # Only update if processing was successful\n",
    "            df.at[i, 'num_sections'] = num_sections\n",
    "            print(f\"Image {row['id']} processed - {num_sections} sections found\")\n",
    "        else:\n",
    "            print(f\"Image {row['id']} processing failed with status code {status_code}\")\n",
    "        \n",
    "        # Save the DataFrame after each image is processed\n",
    "        df.to_csv(\"./Data/metadata.csv\", index=False)\n",
    "        print(\"---\\t---\\t---\\t---\\t---\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "project_id = os.getenv('VERTEXAI_PROJECT_ID')\n",
    "vertexai.init(project=project_id, location=\"us-central1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"./Data/images\"\n",
    "output_dir = f\"./Data/outputs\"\n",
    "\n",
    "df = pd.read_csv(\"./Data/metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 79050514\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79050514 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79042213\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79042213 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79142755\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79142755 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79082901\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79082901 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79089625\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79089625 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120816\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120816 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79121381\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79121381 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79146412\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79146412 processed - 11 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79136659\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79136659 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79127167\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79127167 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79124931\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79124931 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79050210\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79050210 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118490\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118490 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118826\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118826 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79081114\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79081114 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79138170\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79138170 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79145758\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79145758 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79079562\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79079562 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79084966\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79084966 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79042751\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79042751 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79146127\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79146127 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79046052\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79046052 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79085902\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79085902 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79139318\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79139318 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79115093\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79115093 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79084406\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79084406 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143664\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143664 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79139152\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79139152 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79041900\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79041900 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79084609\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79084609 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79139436\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79139436 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79045030\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79045030 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79087096\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79087096 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79121996\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79121996 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79041579\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79041579 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144187\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144187 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79096695\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79096695 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143159\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143159 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118958\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118958 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79097264\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79097264 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79126371\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79126371 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79081164\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79081164 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118274\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118274 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144033\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144033 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79129180\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79129180 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79083932\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79083932 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79142984\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79142984 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79121211\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79121211 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143556\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143556 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79142221\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79142221 processed - 11 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79044080\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79044080 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144988\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144988 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79049664\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79049664 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79123414\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79123414 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79048500\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79048500 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79139703\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79139703 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79126629\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79126629 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120292\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120292 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79093194\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79093194 processed - 13 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120956\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120956 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79122871\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79122871 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79131431\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79131431 processed - 10 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79127434\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79127434 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79114567\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79114567 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79145106\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79145106 processed - 11 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79125174\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79125174 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79115487\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79115487 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144053\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144053 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79132115\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79132115 processed - 11 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79045146\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79045146 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130670\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130670 processed - 10 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79081171\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79081171 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79146548\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79146548 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118923\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118923 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79119961\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79119961 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120927\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120927 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79049369\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79049369 processed - 13 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79048749\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79048749 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79079487\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79079487 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144165\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144165 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79041624\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79041624 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143195\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143195 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79049234\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79049234 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79080719\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79080719 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79041481\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79041481 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144079\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144079 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79047610\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79047610 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130069\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130069 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118138\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118138 processed - 10 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79126749\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79126749 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79078823\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79078823 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79142883\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79142883 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79123619\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79123619 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79045792\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79045792 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79079676\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79079676 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79087062\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79087062 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79129486\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79129486 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79117563\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79117563 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79089559\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79089559 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79122545\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79122545 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79116172\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79116172 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79045307\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79045307 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79044774\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79044774 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79087874\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79087874 processed - 17 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143620\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143620 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79136777\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79136777 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130057\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130057 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118152\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118152 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79127946\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79127946 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79085798\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79085798 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79137268\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79137268 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79146419\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79146419 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79122325\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79122325 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79087767\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79087767 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79118843\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79118843 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79079438\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79079438 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79121278\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79121278 processed - 10 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79122150\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79122150 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120973\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120973 processed - 2 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130522\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130522 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79124400\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79124400 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79083164\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79083164 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79131385\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79131385 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79125244\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79125244 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79093513\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79093513 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79120264\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79120264 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79114987\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79114987 processed - 8 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130607\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130607 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143777\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143777 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144476\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144476 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79090291\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79090291 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130391\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130391 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79088829\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79088829 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79139431\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79139431 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79050338\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79050338 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79129172\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79129172 processed - 7 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79130529\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79130529 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79089650\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79089650 processed - 5 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79048715\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79048715 processed - 9 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79144491\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79144491 processed - 6 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79049633\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79049633 processed - 1 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79143869\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79143869 processed - 3 sections found\n",
      "---\t---\t---\t---\t---\n",
      "Processing image 79131326\n",
      "Text detection completed\n",
      "Unprocessed text saved\n",
      "Paragraphs merged\n",
      "Bounding boxes drawn\n",
      "Text removed from image\n",
      "Vertical and horizontal lines detected\n",
      "Sections created and merged\n",
      "Image 79131326 processed - 4 sections found\n",
      "---\t---\t---\t---\t---\n"
     ]
    }
   ],
   "source": [
    "df = process_images_and_update_csv(df, img_dir, output_dir, project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read both CSV files\n",
    "filtered_data = pd.read_csv('Data/filtered_data.csv')\n",
    "metadata = pd.read_csv('Data/metadata.csv')\n",
    "\n",
    "# Filter the filtered_data to keep only rows where Id exists in metadata's id\n",
    "filtered_result = filtered_data[filtered_data['Id'].isin(metadata['id'])]\n",
    "\n",
    "# Save the filtered result back to CSV\n",
    "filtered_result.to_csv('Data/filtered_data_matched.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "York",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
